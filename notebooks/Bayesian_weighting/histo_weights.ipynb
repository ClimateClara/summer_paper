{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Look at the distribution of the weights for different sigma_mod\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "import multimelt.useful_functions as uf\n",
    "import os\n",
    "from xhistogram.xarray import histogram\n",
    "import scipy.io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('paper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "READ IN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_path = '/bettik/burgardc/'\n",
    "plot_path = '/bettik/burgardc/PLOTS/summer_paper_plots/'\n",
    "outputpath_GL = '/bettik/burgardc/DATA/SUMMER_PAPER/processed/GL_FLUX/'\n",
    "outputpath_weights = '/bettik/burgardc/DATA/SUMMER_PAPER/processed/ANALYSIS/'\n",
    "inputpath_raw = '/bettik/burgardc/DATA/SUMMER_PAPER/raw/'\n",
    "inputpath_data=home_path+'/DATA/SUMMER_PAPER/interim/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputpath_mask = home_path+'/DATA/SUMMER_PAPER/interim/ANTARCTICA_IS_MASKS/BedMachine_4km/'\n",
    "file_isf_orig = xr.open_dataset(inputpath_mask+'BedMachinev2_4km_isf_masks_and_info_and_distance_oneFRIS.nc')\n",
    "nonnan_Nisf = file_isf_orig['Nisf'].where(np.isfinite(file_isf_orig['front_bot_depth_max']), drop=True).astype(int)\n",
    "file_isf_nonnan = file_isf_orig.sel(Nisf=nonnan_Nisf)\n",
    "rignot_isf = file_isf_nonnan.Nisf.where(np.isfinite(file_isf_nonnan['isf_area_rignot']), drop=True)\n",
    "file_isf = file_isf_nonnan.sel(Nisf=rignot_isf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the domain a little smaller to make the computation even more efficient - file isf has already been made smaller at its creation\n",
    "map_lim = [-3000000,3000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BedMachine_orig = xr.open_dataset(inputpath_data+'BedMachine_v2_aggregated4km_allvars.nc')\n",
    "file_BedMachine = uf.cut_domain_stereo(BedMachine_orig, map_lim, map_lim)\n",
    "file_isf_conc = file_BedMachine['isf_conc']\n",
    "\n",
    "grid_cell_area_file = xr.open_dataset(inputpath_data+'gridarea_ISMIP6_AIS_4000m_grid.nc').sel(x=file_isf.x,y=file_isf.y)\n",
    "true_grid_cell_area = grid_cell_area_file['cell_area'].drop('lon').drop('lat')\n",
    "cell_area_weight = true_grid_cell_area/(4000 * 4000)\n",
    "\n",
    "lon = file_isf.longitude\n",
    "lat = file_isf.latitude\n",
    "\n",
    "xx = file_isf.x\n",
    "yy = file_isf.y\n",
    "dx = (xx[2] - xx[1]).values\n",
    "dy = (yy[2] - yy[1]).values\n",
    "grid_cell_area_const = abs(dx*dy)  \n",
    "grid_cell_area_weighted = file_isf_conc * grid_cell_area_const * cell_area_weight\n",
    "\n",
    "isf_stack_mask = uf.create_stacked_mask(file_isf['ISF_mask'], file_isf.Nisf, ['y','x'], 'mask_coord')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_list = []\n",
    "for kisf in tqdm(file_isf.Nisf):\n",
    "    true_grid_cell_area_kisf = uf.choose_isf(grid_cell_area_weighted ,isf_stack_mask, kisf) \n",
    "    area_list.append(true_grid_cell_area_kisf.sum().assign_coords({'Nisf': kisf}))\n",
    "area_BedMachine = xr.concat(area_list, dim = 'Nisf')/10**6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_isf_rignot = [11,69,43,28,12,57,\n",
    "                     70,44,29,13,58,71,45,30,14,\n",
    "                     59,72,46,\n",
    "                     31,\n",
    "                     15,61,73,47,32,16,48,33,17,62,49,34,18,63,74,\n",
    "                     50,35,19,64,\n",
    "                     10,\n",
    "                     36,20,65,51,37,\n",
    "                     22,38,52,23,66,53,39,24,\n",
    "                     67,40,54,75,25,41,\n",
    "                     26,42,55,68,60,27]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "REFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputpath_davison = home_path+'/DATA/SUMMER_PAPER/raw/'\n",
    "davison_file0 = xr.open_dataset(inputpath_davison + 'steadystate_davison23.nc')\n",
    "davison_file = xr.open_dataset(inputpath_davison + 'varying_conditions_davison23.nc')\n",
    "greene_file = xr.open_dataset(inputpath_davison + 'area_isf_greene22.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_balance_davison_steady = davison_file0['basal_melt_obs'] - davison_file0['SMB_obs'] + davison_file0['calving_obs'] - davison_file0['discharge_obs']\n",
    "mass_balance_davison_steady_unc = np.sqrt(davison_file0['basal_melt_unc']**2 + davison_file0['SMB_unc']**2 + davison_file0['calving_obs']**2 + davison_file0['discharge_unc']**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_balance_davison_varying = davison_file['melt_abs'] - davison_file['SMB_abs'] + davison_file0['calving_obs'] - davison_file['discharge_abs']\n",
    "mass_balance_davison_varying_unc = np.sqrt(davison_file['melt_unc']**2 + davison_file['SMB_unc']**2 + davison_file0['calving_unc']**2 + davison_file['discharge_unc']**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "SMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputpath_atmo_Chris = '/bettik/burgardc/DATA/SUMMER_PAPER/raw/TS_SMB_DATA/out2/'\n",
    "inputpath_atmo_Nico = '/bettik/burgardc/DATA/SUMMER_PAPER/interim/SMB_EMULATED/'\n",
    "scenario = 'historical'\n",
    "\n",
    "melt_atmo_list = []\n",
    "for mod in ['CESM2','CNRM-CM6-1','IPSL-CM6A-LR','MPI-ESM1-2-HR','UKESM1-0-LL']:\n",
    "    if os.path.exists(inputpath_atmo_Chris+mod+'_SMB_'+scenario+'-1980-2014.nc'):\n",
    "        melt_atmo = xr.open_dataset(inputpath_atmo_Chris+mod+'_SMB_'+scenario+'-1980-2014.nc').sel(Nisf=rignot_isf)\n",
    "        melt_atmo['time'] = melt_atmo['time'].dt.year\n",
    "        melt_atmo_list.append(melt_atmo['SMB'].assign_coords({'model': mod}))\n",
    "    else:\n",
    "        melt_atmo = xr.open_dataset(inputpath_atmo_Nico+mod+'_SMB_'+scenario+'-1980-2014.nc').sel(Nisf=rignot_isf)\n",
    "        melt_atmo_list.append(melt_atmo['SMB'].assign_coords({'model': mod}))\n",
    "        \n",
    "for mod in ['ACCESS-ESM1-5','ACCESS-CM2','CESM2-WACCM','CNRM-ESM2-1',\n",
    "            'CanESM5','GFDL-CM4','GFDL-ESM4','GISS-E2-1-H', \n",
    "           'MRI-ESM2-0']:\n",
    "    melt_atmo = xr.open_dataset(inputpath_atmo_Nico+mod+'_SMB_'+scenario+'-1980-2014.nc').sel(Nisf=rignot_isf)\n",
    "    melt_atmo_list.append(melt_atmo['SMB'].assign_coords({'model': mod}))\n",
    "    \n",
    "melt_atmo_all = xr.concat(melt_atmo_list, dim='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "melt_atmo_all_corr = melt_atmo_all / area_BedMachine * greene_file['area_abs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "BASAL MELT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_classic_list = ['linear_local',\n",
    "              'quadratic_local','quadratic_local_locslope',\n",
    "              'lazero19',\n",
    "              'boxes_4_pismyes_picopno']\n",
    "\n",
    "param_NN_list = ['NNsmall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Melt outputpath\n",
    "Gt_allmod_list = []\n",
    "box1_allmod_list = []\n",
    "\n",
    "scenario = 'historical'\n",
    "for mod in ['ACCESS-ESM1-5','ACCESS-CM2','CESM2','CESM2-WACCM','CNRM-CM6-1','CNRM-ESM2-1',\n",
    "            'CanESM5','GFDL-CM4','GFDL-ESM4','GISS-E2-1-H', 'IPSL-CM6A-LR',\n",
    "           'MPI-ESM1-2-HR','MRI-ESM2-0','UKESM1-0-LL']: #\n",
    "    \n",
    "    outputpath_melt = '/bettik/burgardc/DATA/SUMMER_PAPER/processed/OCEAN_MELT_RATE_CMIP/'+mod+'/'\n",
    "\n",
    "    melt1D_list = []\n",
    "    for mparam in param_classic_list:\n",
    "        melt1D_scenario = xr.open_dataset(outputpath_melt + 'eval_metrics_1D_'+mparam+'_'+scenario+'_oneFRIS_anoISMIP.nc')\n",
    "        melt1D_list.append(melt1D_scenario.assign_coords({'param':mparam}))\n",
    "    melt1D_classic = xr.concat(melt1D_list, dim='param')       \n",
    "    Gt_classic = melt1D_classic['melt_1D_Gt_per_y'].sel(time=range(1980,2015))\n",
    "\n",
    "    melt1D_list = []\n",
    "    for mparam in param_NN_list:\n",
    "        melt1D_scenario = xr.open_dataset(outputpath_melt + 'evalmetrics_1D_'+mparam+'_'+scenario+'_anoISMIP.nc')\n",
    "        melt1D_list.append(melt1D_scenario.assign_coords({'param':mparam}))\n",
    "    melt1D_NN = xr.concat(melt1D_list, dim='param')   \n",
    "    Gt_NN = melt1D_NN['predicted_melt'].sel(metrics='Gt')\n",
    "\n",
    "    Gt_all = xr.concat([Gt_classic, Gt_NN], dim='param')\n",
    "    \n",
    "    Gt_allmod_list.append(Gt_all.assign_coords({'model': mod}))\n",
    "\n",
    "Gt_allmod = xr.concat(Gt_allmod_list, dim='model').sel(time=range(1980,2015))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gt_allmod_corr = Gt_allmod / area_BedMachine * greene_file['area_abs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Melt outputpath\n",
    "Gt_allmod_list = []\n",
    "box1_allmod_list = []\n",
    "\n",
    "scenario = 'historical'\n",
    "for mod in ['ACCESS-ESM1-5','ACCESS-CM2','CESM2','CESM2-WACCM','CNRM-CM6-1','CNRM-ESM2-1',\n",
    "            'CanESM5','GFDL-CM4','GFDL-ESM4','GISS-E2-1-H', 'IPSL-CM6A-LR',\n",
    "           'MPI-ESM1-2-HR','MRI-ESM2-0','UKESM1-0-LL']: #\n",
    "    \n",
    "    outputpath_melt = '/bettik/burgardc/DATA/SUMMER_PAPER/processed/OCEAN_MELT_RATE_CMIP/'+mod+'/'\n",
    "\n",
    "    melt1D_list = []\n",
    "    for mparam in param_classic_list:\n",
    "        melt1D_scenario = xr.open_dataset(outputpath_melt + 'eval_metrics_1D_'+mparam+'_'+scenario+'_oneFRIS_anoNEMO.nc')\n",
    "        melt1D_list.append(melt1D_scenario.assign_coords({'param':mparam}))\n",
    "    melt1D_classic = xr.concat(melt1D_list, dim='param')       \n",
    "    Gt_classic = melt1D_classic['melt_1D_Gt_per_y'].sel(time=range(1980,2015))\n",
    "\n",
    "    melt1D_list = []\n",
    "    for mparam in param_NN_list:\n",
    "        melt1D_scenario = xr.open_dataset(outputpath_melt + 'evalmetrics_1D_'+mparam+'_'+scenario+'_anoNEMO.nc')\n",
    "        melt1D_list.append(melt1D_scenario.assign_coords({'param':mparam}))\n",
    "    melt1D_NN = xr.concat(melt1D_list, dim='param')   \n",
    "    Gt_NN = melt1D_NN['predicted_melt'].sel(metrics='Gt')\n",
    "\n",
    "    Gt_all = xr.concat([Gt_classic, Gt_NN], dim='param')\n",
    "    \n",
    "    Gt_allmod_list.append(Gt_all.assign_coords({'model': mod}))\n",
    "\n",
    "Gt_allmod_anoNEMO = xr.concat(Gt_allmod_list, dim='model').sel(time=range(1980,2015))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gt_allmod_anoNEMO_corr = Gt_allmod_anoNEMO / area_BedMachine * greene_file['area_abs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "GL FLUX ABUMIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GL_flux_ABUMIP = xr.open_dataset(outputpath_GL + 'all_GL_fluxes.nc')\n",
    "GL_flux = xr.open_dataset(outputpath_GL + 'all_GL_fluxes_varying_m.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "GL_flux_ag = xr.Dataset()\n",
    "GL_flux_ag['flux_Gt_ref'] = xr.concat([GL_flux['flux_Gt_ref_m1'].assign_coords({'m': 1}),\n",
    "                                       GL_flux['flux_Gt_ref_m3'].assign_coords({'m': 3}),\n",
    "                                       GL_flux['flux_Gt_ref_m5'].assign_coords({'m': 5})], dim='m')\n",
    "GL_flux_ag['flux_Gt_ABUMIP'] = xr.concat([GL_flux['flux_Gt_ABUMIP_m1'].assign_coords({'m': 1}),\n",
    "                                       GL_flux['flux_Gt_ABUMIP_m3'].assign_coords({'m': 3}),\n",
    "                                       GL_flux['flux_Gt_ABUMIP_m5'].assign_coords({'m': 5})], dim='m')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "SUM OF ALL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_balance_simu_anoISMIP = Gt_allmod_corr - melt_atmo_all_corr + davison_file0['calving_obs'] - GL_flux_ag['flux_Gt_ref']\n",
    "mass_balance_simu_anoNEMO = Gt_allmod_anoNEMO_corr - melt_atmo_all_corr + davison_file0['calving_obs'] - GL_flux_ag['flux_Gt_ref']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "SENSITIVITY EXPERIMENTS AND LOOK AT DISTRIBUTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "ano_choice = xr.open_dataset(outputpath_weights + 'NEMOorISMIP_choice_and_weights.nc')['ano_choice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_balance_simu_combined_list = []\n",
    "\n",
    "for kisf in file_isf.Nisf:\n",
    "    if ano_choice.sel(Nisf=kisf).values == 'NEMO':\n",
    "        mass_balance_simu_combined_list.append(mass_balance_simu_anoNEMO.sel(Nisf=kisf))\n",
    "        \n",
    "    elif ano_choice.sel(Nisf=kisf).values == 'ISMIP':\n",
    "        mass_balance_simu_combined_list.append(mass_balance_simu_anoISMIP.sel(Nisf=kisf))\n",
    "\n",
    "mass_balance_simu_combined = xr.concat(mass_balance_simu_combined_list, dim='Nisf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_fac = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_mod_obs = mass_balance_simu_combined.mean('time') - mass_balance_davison_varying.mean('time') \n",
    "\n",
    "sigma_obs = mass_balance_davison_varying_unc.mean('time')\n",
    "sigma_mod = mass_balance_simu_combined.std('time').mean(['model','param','m']) * mult_fac\n",
    "\n",
    "s_j = np.exp(-((diff_mod_obs)**2/(sigma_obs**2 + sigma_mod**2))) \n",
    "\n",
    "weight = (s_j / (s_j.sum(['model','param','m'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f = plt.figure()\n",
    "\n",
    "for i,ddim in enumerate(['param','model','m']): #\n",
    "\n",
    "    if ddim == 'param':\n",
    "        weight_ddim = weight.stack(stack_dim=['model','m','Nisf'])\n",
    "    elif ddim == 'model':\n",
    "        weight_ddim = weight.stack(stack_dim=['param','m','Nisf'])\n",
    "    elif ddim == 'm':        \n",
    "        weight_ddim = weight.stack(stack_dim=['param','model','Nisf'])\n",
    "\n",
    "\n",
    "    bins = weight_ddim[ddim]\n",
    "    _, bin_edges = np.histogram(weight_ddim.values, bins=np.arange(len(bins)), weights=weight_ddim.values)\n",
    "\n",
    "    hist = weight_ddim.sum('stack_dim') # / weight_ddim.sum()\n",
    "\n",
    "    ax[i] = f.add_subplot(1,3,i+1)\n",
    "    ax[i].barh(weight_ddim[ddim], hist,  edgecolor='black') #width=1,\n",
    "    ax[i].set_title('sigma_mod = '+str(mult_fac)+' x std deviation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for kisf in sorted_isf_rignot:\n",
    "        f = plt.figure()\n",
    "\n",
    "        for i,ddim in enumerate(['param','model','m']): #\n",
    "\n",
    "            if ddim == 'param':\n",
    "                weight_ddim = weight.sel(Nisf=kisf).stack(stack_dim=['model','m'])\n",
    "            elif ddim == 'model':\n",
    "                weight_ddim = weight.sel(Nisf=kisf).stack(stack_dim=['param','m'])\n",
    "            elif ddim == 'm':        \n",
    "                weight_ddim = weight.sel(Nisf=kisf).stack(stack_dim=['param','model'])\n",
    "\n",
    "    \n",
    "            bins = weight_ddim[ddim]\n",
    "            _, bin_edges = np.histogram(weight_ddim.values, bins=np.arange(len(bins)), weights=weight_ddim.values)\n",
    "\n",
    "            hist = weight_ddim.sum('stack_dim') # / weight_ddim.sum()\n",
    "            \n",
    "            ax[i] = f.add_subplot(1,3,i+1)\n",
    "            ax[i].barh(weight_ddim[ddim], hist,  edgecolor='black') #width=1,\n",
    "            ax[i].set_title('sigma_mod = '+str(mult_fac)+' x std deviation')\n",
    "        f.suptitle(file_isf['isf_name'].sel(Nisf=kisf).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### THINK ABOUT THE SIGMA_MOD AND SIGMA_OBS AGAIN\n",
    "\n",
    "regions = ['Weddell','Bellingshausen','Amundsen','Ross','East 1','East 2','Dronning Maud Land']\n",
    "colors = ['red','orange','gold','mediumturquoise','maroon','magenta','cornflowerblue','lightseagreen',\n",
    "          'yellowgreen','royalblue','tomato','darkslateblue','purple','darkgoldenrod']\n",
    "\n",
    "f = plt.figure()\n",
    "f.set_size_inches(8.25*3, 8.25*3)\n",
    "\n",
    "ax={}\n",
    "\n",
    "leg_hdl = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "sigma_tot_1 = np.sqrt(sigma_obs**2 + sigma_mod**2)\n",
    "#sigma_tot_2 = np.sqrt(sigma_obs**2 + sigma_mod**2)\n",
    "#sigma_tot_5 = np.sqrt(sigma_obs**2 + sigma_mod**2)\n",
    "#sigma_tot_10 = np.sqrt(sigma_obs**2 + sigma_mod**2)\n",
    "\n",
    "\n",
    "\n",
    "for kisf in tqdm(sorted_isf_rignot):\n",
    "    \n",
    "    ax[i] = f.add_subplot(8,8,i+1)\n",
    "    \n",
    "    melt_obs_kisf = mass_balance_davison_varying.sel(Nisf=kisf).sel(time=range(1997,2015)).mean('time')\n",
    "    melt_obs_unc_kisf = mass_balance_davison_varying_unc.sel(Nisf=kisf).sel(time=range(1997,2015)).mean('time')\n",
    "    ax[i].axhline(y=melt_obs_kisf,color='k')\n",
    "    ax[i].fill_between(x=range(1997,2015), y1=melt_obs_kisf-melt_obs_unc_kisf, y2=melt_obs_kisf+melt_obs_unc_kisf, color='lightgrey')\n",
    "    #ax[i].fill_between(x=range(1997,2015), y1=melt_obs_kisf-sigma_tot_10.sel(Nisf=kisf), y2=melt_obs_kisf+sigma_tot_10.sel(Nisf=kisf), color='lightgrey',alpha=0.2)\n",
    "    #ax[i].fill_between(x=range(1997,2015), y1=melt_obs_kisf-sigma_tot_5.sel(Nisf=kisf), y2=melt_obs_kisf+sigma_tot_5.sel(Nisf=kisf), color='lightgrey',alpha=0.4)\n",
    "    #ax[i].fill_between(x=range(1997,2015), y1=melt_obs_kisf-sigma_tot_2.sel(Nisf=kisf), y2=melt_obs_kisf+sigma_tot_2.sel(Nisf=kisf), color='lightgrey',alpha=0.6)\n",
    "    ax[i].fill_between(x=range(1997,2015), y1=melt_obs_kisf-sigma_tot_1.sel(Nisf=kisf), y2=melt_obs_kisf+sigma_tot_1.sel(Nisf=kisf), color='lightgrey',alpha=0.8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for mmodel in mass_balance_simu_combined.model:\n",
    "        for m in mass_balance_simu_combined.m:\n",
    "            for mparam in mass_balance_simu_combined.param:\n",
    "                ax[i].plot(mass_balance_simu_combined.time, mass_balance_simu_combined.sel(param=mparam,Nisf=kisf,m=m, model=mmodel), color='deepskyblue',alpha=0.05)\n",
    "\n",
    "    #ax[i].plot(ensstat_weighted.time, ensstat_nonweighted.sel(quantile=0.5,Nisf=kisf), color='deepskyblue')\n",
    "    #ax[i].fill_between(x=ensstat_weighted_combined.time, y1=ensstat_weighted_combined.sel(quantile=0.33,Nisf=kisf), y2=ensstat_weighted_combined.sel(quantile=0.66,Nisf=kisf), color='deepskyblue',alpha=0.2)\n",
    "\n",
    "    #if kisf == 23:\n",
    "    #    ax[i].set_title('Tracy Tremenchus')\n",
    "    #elif kisf == 24:\n",
    "    #    ax[i].set_title('Conger/Glenzer')\n",
    "    #elif kisf == 110:\n",
    "    #    ax[i].set_title('Ekström')\n",
    "    #else:\n",
    "    ax[i].set_title(str(file_isf['isf_name'].sel(Nisf=kisf).values))\n",
    "\n",
    "    #ax[i].set_xlim(0,60)\n",
    "    #ax[i].axvline(x=30, c='k', linestyle='--')\n",
    "\n",
    "    i = i+1\n",
    "\n",
    "#f.legend()\n",
    "#f.subplots_adjust(bottom=0.05, wspace=0.1)\n",
    "\n",
    "f.tight_layout()\n",
    "sns.despine()\n",
    "f.savefig(plot_path + 'checking_sigma_mod.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ddim in ['m']: #'param','model',\n",
    "    \n",
    "    if ddim == 'param':\n",
    "        weight_ddim = weight.stack(stack_dim=['model','m','Nisf'])\n",
    "    elif ddim == 'model':\n",
    "        weight_ddim = weight.stack(stack_dim=['param','m','Nisf'])\n",
    "    elif ddim == 'm':        \n",
    "        weight_ddim = weight.stack(stack_dim=['param','model','Nisf'])\n",
    "        \n",
    "    xr_ddim, _ = xr.broadcast(weight_ddim[ddim], weight_ddim)\n",
    "\n",
    "    arr_range = xr_ddim.copy()\n",
    "    for nn, mdim in enumerate(xr_ddim[ddim].values):\n",
    "        arr_range = arr_range.where(xr_ddim != mdim, nn)\n",
    "    \n",
    "    # Define bins\n",
    "    bins = np.arange(len(weight_ddim[ddim]))\n",
    "\n",
    "    # Compute histogram\n",
    "    hist, bin_edges = np.histogram(arr_range.values, bins=np.arange(len(bins)), weights=weight_ddim.values)\n",
    "    \n",
    "    plt.figure()\n",
    "    # Normalize histogram by weights\n",
    "    hist = hist / weight_ddim.sum().values\n",
    "\n",
    "    # Plot the weighted histogram\n",
    "    plt.bar(bin_edges[:-1], hist, width=np.diff(bin_edges), edgecolor='black')\n",
    "    \n",
    "    plt.title(ddim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_range.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_ddim.sel(m=3).sum('stack_dim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_param.sum().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "LHS = scipy.io.loadmat('/bettik/burgardc/DATA/SUMMER_PAPER/raw/LHSensemble.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.io.whosmat('/bettik/burgardc/DATA/SUMMER_PAPER/raw/LHSensemble.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = LHS['LHS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "histogram(xr_param.rename('test'), weights=weight_param) #, weights=weight , bins=weight.param.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_param.rename('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "N, edges = np.histogram(data, bins=len(weight_param.param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_histogram(data, w, bin_number):\n",
    "    N, edges = np.histogram(data, bins=bin_number)  # histogram without weight for edges and normalization\n",
    "    bin_center = (edges[:-1] + edges[1:]) / 2\n",
    "\n",
    "    N_noweight = N  # save N without weight -- used for normalization\n",
    "    N = np.zeros_like(N)\n",
    "\n",
    "    # calculate N per bin\n",
    "    for i in range(len(data)):\n",
    "        for b in range(len(edges) - 1):\n",
    "            if edges[b] <= data[i] <= edges[b + 1]:\n",
    "                N[b] += w[i]\n",
    "\n",
    "    N /= N_noweight  # normalization for pdf\n",
    "\n",
    "    return bin_center, N"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
