{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Prepare Paolo et al. 2023 basal melt to use in summer paper\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputpath_raw = '/bettik/burgardc/DATA/SUMMER_PAPER/raw/'\n",
    "home_path = '/bettik/burgardc/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputpath_mask = home_path+'/DATA/SUMMER_PAPER/interim/ANTARCTICA_IS_MASKS/BedMachine_4km/'\n",
    "file_isf_orig = xr.open_dataset(inputpath_mask+'BedMachinev2_4km_isf_masks_and_info_and_distance_oneFRIS.nc')\n",
    "nonnan_Nisf = file_isf_orig['Nisf'].where(np.isfinite(file_isf_orig['front_bot_depth_max']), drop=True).astype(int)\n",
    "file_isf_nonnan = file_isf_orig.sel(Nisf=nonnan_Nisf)\n",
    "rignot_isf = file_isf_nonnan.Nisf.where(np.isfinite(file_isf_nonnan['isf_area_rignot']), drop=True)\n",
    "file_isf = file_isf_nonnan.sel(Nisf=rignot_isf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputpath_Paolo_processed = '/bettik/millanr/DATA_SERVER/ANTARCTICA/OCEANICE/DATASET_FINAL/'\n",
    "integrated_Paolo = pd.read_csv(inputpath_Paolo_processed + 'Merged_Integrated_melt_rates.csv',index_col=0)\n",
    "Paolo_Gt_ds = integrated_Paolo.to_xarray()\n",
    "\n",
    "inputpath_Paolo_processed = '/bettik/millanr/DATA_SERVER/ANTARCTICA/OCEANICE/DATASET_FINAL/'\n",
    "integrated_Paolo_unc = pd.read_csv(inputpath_Paolo_processed + 'Merged_Integrated_melt_err_rates.csv',index_col=0)\n",
    "Paolo_Gt_unc_ds = integrated_Paolo_unc.to_xarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_list = ['1992'] + np.arange(1994,2015).astype(str).tolist()\n",
    "#year_list = np.arange(1992,2015).astype(str).tolist()\n",
    "merged_list = []\n",
    "merged_list_unc = []\n",
    "for vvar in year_list:\n",
    "    merged_list.append(Paolo_Gt_ds[vvar].rename('melt_Gt').assign_coords({'time': int(vvar)}))\n",
    "    merged_list_unc.append(Paolo_Gt_unc_ds[vvar].rename('melt_Gt_unc').assign_coords({'time': int(vvar)}))\n",
    "merged_ds = xr.concat(merged_list, dim='time')\n",
    "merged_unc_ds = xr.concat(merged_list_unc, dim='time')\n",
    "merged_ds_both = xr.merge([merged_ds,merged_unc_ds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "melt_Gt_list = []\n",
    "for kisf in file_isf.Nisf:\n",
    "    nname = file_isf['isf_name'].sel(Nisf=kisf).values\n",
    "    if nname in merged_ds['Names']:\n",
    "        melt_Gt_kisf = merged_ds_both.sel(Names=nname).squeeze().drop('Names')\n",
    "    elif nname == 'Conger/Glenzer':\n",
    "        melt_Gt_kisf = merged_ds_both.sel(Names='Conger_Glenzer').squeeze().drop('Names')\n",
    "    elif nname == 'George VI':\n",
    "        melt_Gt_kisf = merged_ds_both.sel(Names='George_VI').squeeze().drop('Names')\n",
    "    elif str(nname)[0:7] == 'Larsen ':\n",
    "        melt_Gt_kisf = merged_ds_both.sel(Names='Larsen'+str(nname)[7]).squeeze().drop('Names')\n",
    "    elif nname == 'Prince Harald':\n",
    "        melt_Gt_kisf = merged_ds_both.sel(Names='Prince_Harald').squeeze().drop('Names')\n",
    "    elif nname == 'Moscow Univ.':    \n",
    "        melt_Gt_kisf = merged_ds_both.sel(Names='Moscow_University').squeeze().drop('Names')\n",
    "    elif nname == 'Roi Baudouin':\n",
    "        melt_Gt_kisf = merged_ds_both.sel(Names='Baudouin').squeeze().drop('Names')\n",
    "    elif nname == 'Wilma/Robert/Downer':\n",
    "        melt_Gt_kisf = merged_ds_both.sel(Names='WilmaRobertDowner').squeeze().drop('Names')\n",
    "    elif nname == 'Tracy Tremenchus':\n",
    "        melt_Gt_kisf = merged_ds_both.sel(Names='Tracy_Tremenchus').squeeze().drop('Names')\n",
    "    elif nname == 'Rayner/Thyer':\n",
    "        melt_Gt_kisf = merged_ds_both.sel(Names='Rayner_Thyer').squeeze().drop('Names')\n",
    "    elif nname == 'Pine Island':\n",
    "        melt_Gt_kisf = merged_ds_both.sel(Names='Pine_Island').squeeze().drop('Names')\n",
    "    elif nname == 'Stancomb Brunt':\n",
    "        melt_Gt_kisf = merged_ds_both.sel(Names='Brunt_Stancomb').squeeze().drop('Names')\n",
    "    elif nname == 'Edward VIII':\n",
    "        melt_Gt_kisf = merged_ds_both.sel(Names='Edward_VIII').squeeze().drop('Names')\n",
    "    elif nname == 'Vincennes Bay':\n",
    "        melt_Gt_kisf = merged_ds_both.sel(Names='Vincennes_Bay').squeeze().drop('Names')\n",
    "    elif nname == 'Filchner-Ronne':\n",
    "        melt_abs = merged_ds_both['melt_Gt'].sel(Names='Ronne').squeeze().drop('Names') + merged_ds_both['melt_Gt'].sel(Names='Filchner').squeeze().drop('Names')\n",
    "        melt_unc = np.sqrt(merged_ds_both['melt_Gt_unc'].sel(Names='Ronne').squeeze().drop('Names')**2 \n",
    "                           + merged_ds_both['melt_Gt_unc'].sel(Names='Filchner').squeeze().drop('Names')**2)\n",
    "        melt_Gt_kisf = xr.merge([melt_abs,melt_unc])\n",
    "    elif nname == 'Ross':\n",
    "        melt_abs = merged_ds_both['melt_Gt'].sel(Names='Ross_East').squeeze().drop('Names') + merged_ds_both['melt_Gt'].sel(Names='Ross_West').squeeze().drop('Names')\n",
    "        melt_unc = np.sqrt(merged_ds_both['melt_Gt_unc'].sel(Names='Ross_East').squeeze().drop('Names')**2 \n",
    "                           + merged_ds_both['melt_Gt_unc'].sel(Names='Ross_West').squeeze().drop('Names')**2)\n",
    "        melt_Gt_kisf = xr.merge([melt_abs,melt_unc])\n",
    "    \n",
    "    elif nname == 'Wordie':\n",
    "        melt_abs = (merged_ds_both['melt_Gt'].sel(Names='Wordie_(Harriott)').squeeze().drop('Names') \n",
    "                    + merged_ds_both['melt_Gt'].sel(Names='Wordie_(Harriott_Headland)').squeeze().drop('Names')\n",
    "                    + merged_ds_both['melt_Gt'].sel(Names='Wordie_(Cape_Jeremy)').squeeze().drop('Names')\n",
    "                    + merged_ds_both['melt_Gt'].sel(Names='Wordie_(Prospect)').squeeze().drop('Names')\n",
    "                    + merged_ds_both['melt_Gt'].sel(Names='Wordie_(Airy_Rotz_Seller)').squeeze().drop('Names')\n",
    "                   )\n",
    "        melt_unc = np.sqrt(merged_ds_both['melt_Gt_unc'].sel(Names='Wordie_(Harriott)').squeeze().drop('Names')**2 \n",
    "                    + merged_ds_both['melt_Gt_unc'].sel(Names='Wordie_(Harriott_Headland)').squeeze().drop('Names')**2 \n",
    "                    + merged_ds_both['melt_Gt_unc'].sel(Names='Wordie_(Cape_Jeremy)').squeeze().drop('Names')**2 \n",
    "                    + merged_ds_both['melt_Gt_unc'].sel(Names='Wordie_(Prospect)').squeeze().drop('Names')**2 \n",
    "                    + merged_ds_both['melt_Gt_unc'].sel(Names='Wordie_(Airy_Rotz_Seller)').squeeze().drop('Names')**2 \n",
    "                   )\n",
    "        melt_Gt_kisf = xr.merge([melt_abs,melt_unc])\n",
    "                    \n",
    "    melt_Gt_list.append(melt_Gt_kisf.assign_coords({'Nisf': kisf}))\n",
    "\n",
    "melt_Gt_all_Paolo = xr.concat(melt_Gt_list, dim='Nisf')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "melt_Gt_all_Paolo.to_netcdf(outputpath_raw + 'basal_melt_Gt_Paolo23.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
