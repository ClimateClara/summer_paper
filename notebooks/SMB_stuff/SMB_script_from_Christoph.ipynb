{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Fri Nov 24 15:28 2023\n",
    "\n",
    "SMB formatting from Christoph\n",
    "\n",
    "Author: @claraburgard\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "#from matplotlib.font_manager import FontProperties\n",
    "#import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import cftime\n",
    "#import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMBcomponents_to_gt(SMB_array, nisf,mask,ice_frac,data_start=1980, data_end=2100):\n",
    "    \"\"\" This function returns a daily time series of absolute SMB component values, expressed as gigatons. 35 000 m = MAR resolution 1e12 factor to convert kg/m² in Gt \"\"\"\n",
    "    \n",
    "    ice=ice_frac.where(mask.values==nisf)\n",
    "    reso=4.*1000.\n",
    "    data = SMB_array*ice.values#*area.values\n",
    "    # Make sure only wanted time frame is used\n",
    "    #data = data.loc[str(data_start) + ‘-01-01’:str(data_end) + ‘-12-31’]\n",
    "    # Convert to gigatons and sum up spatially over the AIS\n",
    "    sum_spatial = data.sum(dim=['x', 'y']) * ((reso * reso) / (1e12))\n",
    "    return sum_spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# # OPEN the ICE MASK\n",
    "# =============================================================================\n",
    "mask = xr.open_dataset('BedMachinev2_4km_isf_masks_and_info_and_distance_oneFRIS.nc'\n",
    "            ,decode_times=False)\n",
    "\n",
    "isfarea=mask[\"isf_area_rignot\"]\n",
    "names=mask[\"isf_name\"]\n",
    "nisf_values=mask['Nisf'].values\n",
    "mask=mask['ISF_mask']\n",
    "\n",
    "ice=xr.open_dataset(\"BedMachine_v2_aggregated4km_allvars_cut.nc\")\n",
    "ice=ice[\"isf_conc\"]\n",
    "forcing='ACCESS1.3'\n",
    "yearstart=1980\n",
    "yearend=2100\n",
    "ssp='rcp8.5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# # Create the future xarray dataset\n",
    "# =============================================================================\n",
    "# Generate nisf and time dimensions\n",
    "# Generate nisf and time dimensions\n",
    "#nisf_values = np.arange(0, 64, 1) # From 0 to 216\n",
    "time_values = np.arange(yearstart, yearend+1, 1) # From 1980 to 2100 #will be converted later with a real time\n",
    "# Generate random data for the dataset\n",
    "data1 = np.random.rand(len(nisf_values), len(time_values))*0\n",
    "data2 = np.random.rand(len(nisf_values), len(time_values))*0\n",
    "dates = xr.cftime_range(start=str(yearstart)+\"-01-01\", end=str(yearend)+\"-12-31\", freq='AS')\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# # OPEN the SMB file\n",
    "# =============================================================================\n",
    "var_list=[“SMB”,“RU”,“SF”,“RF”,“ME”]\n",
    "var_list=[“SMB”]\n",
    "for var in var_list:\n",
    "    MAR=xr.open_dataset(\"in/MAR3.11-\"+forcing+\"_\"+ssp+\"-onbedmachinev2-4km_\"+str(yearstart)+\"-\"+str(yearend)+\".nc\",decode_times=False)\n",
    "    MAR[\"time\"]=dates\n",
    "    # Create the xarray dataset\n",
    "    dataset = xr.Dataset(\n",
    "    data_vars={var: (['Nisf', 'time'], data1),\n",
    "          var+'org': (['Nisf', 'time'], data2)},\n",
    "    coords={‘Nisf’: nisf_values, 'time': dates})\n",
    "    \n",
    "    varint=MAR[var]\n",
    "    varorg=MAR[var+'org']\n",
    "    area=MAR[\"AREA\"]\n",
    "    newice=ice*area.values\n",
    "    MAR[\"time\"]=dates\n",
    "    del(MAR)\n",
    "    for nisf in range(0,len(nisf_values)):\n",
    "        print (nisf,nisf_values[nisf], names.values[nisf])\n",
    "        if np.isfinite(isfarea[nisf].values):\n",
    "            print (nisf, \"ok\")\n",
    "            dataset[var][nisf]=SMBcomponents_to_gt(varint, nisf_values[nisf],mask,newice).values\n",
    "            dataset[var+‘org’][nisf]=SMBcomponents_to_gt(varorg, nisf_values[nisf],mask,newice).values\n",
    "\n",
    "    # Save the xarray dataset to a NetCDF file\n",
    "    historical=dataset.sel(time=slice(\"1980-01-01\",\"2014-12-31\"))\n",
    "    if forcing != \"ERA5\":\n",
    "        ssp585=dataset.sel(time=slice(\"2015-01-01\",str(yearend)+\"-12-31\"))\n",
    "        output_filename = \"./out/\"+forcing+'_'+var+'_'+ssp+'-2015-'+str(yearend)+'.nc'\n",
    "        ssp585.to_netcdf(output_filename)\n",
    "        print(“Xarray dataset saved to “+output_filename)\n",
    "    \n",
    "    output_filename = \"./out/\"+forcing+'_'+var+‘_historical-‘+str(yearstart)+‘-2014.nc’\n",
    "    historical.to_netcdf(output_filename)\n",
    "    print(“Xarray dataset saved to “+output_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
