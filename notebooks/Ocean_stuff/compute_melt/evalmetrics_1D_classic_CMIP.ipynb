{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b9d168-b138-4b6e-9c4f-6e75d0d1390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Apply the uncertainty of the parameters from Burgard et al. 2022 to show that \n",
    "uncertainty from parameters is lower than uncertainty from parameterisations\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c077934d-9455-49a5-9350-d6ca8f36dbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib as mpl\n",
    "import pandas as pd \n",
    "from tqdm.notebook import trange, tqdm\n",
    "import time\n",
    "import multimelt.melt_functions as meltf\n",
    "import multimelt.plume_functions as pf\n",
    "import summer_paper.useful_functions as uf\n",
    "from multimelt.constants import *\n",
    "import seaborn as sns\n",
    "import os, glob\n",
    "import distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ab8f1b-b994-4a65-b2cb-b7a738e36c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#home_path = '/Users/claraburgard/bettik_clara/'\n",
    "home_path='/bettik/burgardc/'\n",
    "#home_path='/data/users/burgardc/bettik_clara/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bc4f12-91d9-4fc1-be6a-29b7c42d047e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = 'UKESM1-0-LL'\n",
    "scenario = 'historical'\n",
    "\n",
    "to2300 = False\n",
    "\n",
    "if scenario == 'historical':\n",
    "    yystart = 1980 #1850\n",
    "    yyend = 2014\n",
    "else:\n",
    "    if to2300:\n",
    "        yystart = 2015\n",
    "        yyend = 2300\n",
    "    else:\n",
    "        yystart = 2015\n",
    "        yyend = 2100   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8359e302-731d-4d96-bb70-f340d2e5b1a6",
   "metadata": {},
   "source": [
    "READ IN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74211da-db83-4406-a3c2-a89f5e1e144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputpath_data=home_path+'/DATA/SUMMER_PAPER/interim/'\n",
    "inputpath_mask = home_path+'/DATA/SUMMER_PAPER/interim/ANTARCTICA_IS_MASKS/BedMachine_4km/'\n",
    "inputpath_profiles = home_path+'/DATA/SUMMER_PAPER/interim/T_S_PROF/CMIP/'+mod+'/'\n",
    "inputpath_plumes = home_path+'/DATA/SUMMER_PAPER/interim/PLUMES/BedMachine_4km/'\n",
    "inputpath_boxes = home_path+'/DATA/SUMMER_PAPER/interim/BOXES/BedMachine_4km/'\n",
    "\n",
    "outputpath_simple_all_old = home_path+'/DATA/BASAL_MELT_PARAM/interim/SIMPLE/nemo_5km_06161821_oneFRIS/'\n",
    "outputpath_simple_all_new = home_path+'/DATA/SUMMER_PAPER/interim/SIMPLE/nemo_5km_orig_christoph_oneFRIS/'\n",
    "outputpath_melt = home_path+'/DATA/SUMMER_PAPER/processed/OCEAN_MELT_RATE_CMIP/'+mod+'/'\n",
    "\n",
    "\n",
    "# make the domain a little smaller to make the computation even more efficient - file isf has already been made smaller at its creation\n",
    "map_lim = [-3000000,3000000]\n",
    "\n",
    "file_isf_orig = xr.open_dataset(inputpath_mask+'BedMachinev2_4km_isf_masks_and_info_and_distance_oneFRIS.nc')\n",
    "nonnan_Nisf = file_isf_orig['Nisf'].where(np.isfinite(file_isf_orig['front_bot_depth_max']), drop=True).astype(int)\n",
    "file_isf_nonnan = file_isf_orig.sel(Nisf=nonnan_Nisf)\n",
    "rignot_isf = file_isf_nonnan.Nisf.where(np.isfinite(file_isf_nonnan['isf_area_rignot']), drop=True)\n",
    "file_isf = file_isf_nonnan.sel(Nisf=rignot_isf)\n",
    "file_isf['isf_name'] = file_isf['isf_name'].astype(str)\n",
    "file_isf['region'] = file_isf['region'].astype(str)\n",
    "\n",
    "BedMachine_orig = xr.open_dataset(inputpath_data+'BedMachine_v2_aggregated4km_allvars.nc')\n",
    "BedMachine_orig_cut = uf.cut_domain_stereo(BedMachine_orig, map_lim, map_lim)\n",
    "file_draft = (BedMachine_orig_cut['thickness'] - BedMachine_orig_cut['surface']).where(file_isf['ISF_mask'] > 1)\n",
    "file_isf_conc = BedMachine_orig_cut['isf_conc']\n",
    "\n",
    "file_TS_list = []\n",
    "for tt in tqdm(range(yystart,yyend+1)):\n",
    "    file_T_orig = xr.open_dataset(inputpath_profiles+'T_mean_prof_50km_contshelf_'+mod+'_'+scenario+'_'+str(tt)+'.nc')\n",
    "    file_S_orig = xr.open_dataset(inputpath_profiles+'S_mean_prof_50km_contshelf_'+mod+'_'+scenario+'_'+str(tt)+'.nc')\n",
    "    file_TS_orig = xr.merge([file_T_orig.rename({'thetao':'theta_ocean'}), file_S_orig.rename({'so':'salinity_ocean'})]).sel(Nisf=rignot_isf).assign_coords({'time': tt})\n",
    "    file_TS_list.append(file_TS_orig)\n",
    "file_TS = xr.concat(file_TS_list, dim='time').rename({'z':'depth'})\n",
    "file_TS['depth'] = -1*file_TS['depth']\n",
    "\n",
    "depth_axis_old = file_TS.depth.values\n",
    "depth_axis_new = np.concatenate((np.zeros(1),depth_axis_old))\n",
    "file_TS_with_shallow = file_TS.interp({'depth': depth_axis_new})\n",
    "\n",
    "grid_cell_area_file = xr.open_dataset(inputpath_data+'gridarea_ISMIP6_AIS_4000m_grid.nc').sel(x=file_isf.x,y=file_isf.y)\n",
    "true_grid_cell_area = grid_cell_area_file['cell_area'].drop('lon').drop('lat')\n",
    "cell_area_weight = true_grid_cell_area/(4000 * 4000)\n",
    "\n",
    "lon = file_isf.longitude\n",
    "lat = file_isf.latitude\n",
    "\n",
    "xx = file_isf.x\n",
    "yy = file_isf.y\n",
    "dx = (xx[2] - xx[1]).values\n",
    "dy = (yy[2] - yy[1]).values\n",
    "grid_cell_area_const = abs(dx*dy)  \n",
    "grid_cell_area_weighted = file_isf_conc * grid_cell_area_const * cell_area_weight\n",
    "\n",
    "ice_draft_pos = file_draft\n",
    "ice_draft_neg = -ice_draft_pos\n",
    "\n",
    "isf_stack_mask = uf.create_stacked_mask(file_isf['ISF_mask'], file_isf.Nisf, ['y','x'], 'mask_coord')\n",
    "\n",
    "box_charac_all_2D = xr.open_dataset(inputpath_boxes + 'BedMachine_4km_boxes_2D_oneFRIS.nc')\n",
    "box_charac_all_1D = xr.open_dataset(inputpath_boxes + 'BedMachine_4km_boxes_1D_oneFRIS.nc')\n",
    "plume_charac = xr.open_dataset(inputpath_plumes+'BedMachine_4km_plume_characteristics.nc')\n",
    "\n",
    "param_var_of_int_2D = file_isf[['ISF_mask', 'latitude', 'longitude', 'dGL']]\n",
    "param_var_of_int_1D = file_isf[['front_bot_depth_avg', 'front_bot_depth_max','isf_name']]\n",
    "\n",
    "geometry_info_2D = plume_charac.merge(param_var_of_int_2D).merge(ice_draft_pos.rename('ice_draft_pos')).merge(grid_cell_area_weighted.rename('grid_cell_area_weighted')).merge(file_isf_conc.rename('isfdraft_conc'))\n",
    "geometry_info_1D = param_var_of_int_1D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262ec64f-fdaf-4de0-beef-d762557fc7d5",
   "metadata": {},
   "source": [
    "SIMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e0d2c3-cc17-4eac-8d85-c67bb1bff2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gammas_new_tuning = xr.open_dataset(outputpath_simple_all_new + 'gammas_simple_ALL.nc')\n",
    "gammas_old_tuning = xr.open_dataset(outputpath_simple_all_old + 'gammas_simple_ALL.nc')\n",
    "gammas_SMALL_tuning = xr.open_dataset(outputpath_simple_all_new + 'gammas_simple_SMALL.nc')\n",
    "gammas_LARGE_tuning = xr.open_dataset(outputpath_simple_all_new + 'gammas_simple_LARGE.nc')\n",
    "\n",
    "simple_param_types = ['linear_local', 'quadratic_local', 'quadratic_local_locslope',\n",
    "                      'quadratic_mixed_mean', 'quadratic_mixed_locslope'] \n",
    "\n",
    "nisf_list_orig = geometry_info_1D.Nisf\n",
    "T_S_profile = file_TS_with_shallow.ffill(dim='depth').bfill(dim='depth')\n",
    "\n",
    "\n",
    "\n",
    "for mparam in simple_param_types:\n",
    "    \n",
    "    eval_1D_list = []\n",
    "    for tuning_sort in ['LARGE','SMALL']: #'old'\n",
    "\n",
    "        if tuning_sort == 'LARGE':\n",
    "            nisf_list = nisf_list_orig.sel(Nisf=[10,11])\n",
    "            gamma = gammas_LARGE_tuning['slope'].sel(param=mparam)\n",
    "        elif tuning_sort == 'SMALL':\n",
    "            nisf_list = nisf_list_orig.drop_sel(Nisf=[10,11])\n",
    "            gamma = gammas_LARGE_tuning['slope'].sel(param=mparam)\n",
    "\n",
    "        eval_1D = meltf.calculate_melt_rate_Gt_and_box1_all_isf(nisf_list, T_S_profile, \n",
    "                                                                geometry_info_2D, geometry_info_1D, isf_stack_mask, \n",
    "                                                                mparam, gamma, U_param=True, \n",
    "                                                                box_charac_2D=box_charac_all_2D, box_charac_1D=box_charac_all_1D, verbose=True)\n",
    "        eval_1D_list.append(eval_1D)\n",
    "        \n",
    "    eval_1D_all = xr.concat(eval_1D_list,dim='Nisf')\n",
    "\n",
    "    eval_1D_all.to_netcdf(outputpath_melt+'eval_metrics_1D_'+mparam+'_'+scenario+'_oneFRIS.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517a6751-645d-421c-92df-99b2d746cfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "nisf_list_orig = geometry_info_1D.Nisf\n",
    "T_S_profile = file_TS_with_shallow.ffill(dim='depth').bfill(dim='depth')\n",
    "\n",
    "\n",
    "#########\n",
    "\n",
    "mparam = 'lazero19'   \n",
    "\n",
    "\n",
    "nisf_list = nisf_list_orig\n",
    "gamma = 6.2e-4\n",
    "E0 = 2.0e-2\n",
    "\n",
    "\n",
    "\n",
    "eval_1D = meltf.calculate_melt_rate_Gt_and_box1_all_isf(nisf_list, T_S_profile, \n",
    "                                                 geometry_info_2D, geometry_info_1D, isf_stack_mask, \n",
    "                                                 mparam, gamma, E0=E0, \n",
    "                                                 box_charac_2D=box_charac_all_2D, box_charac_1D=box_charac_all_1D, verbose=True)\n",
    "\n",
    "        \n",
    "\n",
    "eval_1D.to_netcdf(outputpath_melt+'eval_metrics_1D_'+mparam+'_'+scenario+'_oneFRIS.nc')\n",
    "\n",
    "#########\n",
    "\n",
    "nisf_list_orig = geometry_info_1D.Nisf\n",
    "T_S_profile = file_TS_with_shallow.ffill(dim='depth').bfill(dim='depth')\n",
    "    \n",
    "mparam = 'boxes_4_pismyes_picopno'\n",
    "pism_version = 'yes'\n",
    "nD_config = 4\n",
    "        \n",
    "\n",
    "nisf_list = nisf_list_orig\n",
    "gamma = 0.87e-5\n",
    "C = 2.8e6\n",
    "        \n",
    "eval_1D = meltf.calculate_melt_rate_Gt_and_box1_all_isf(nisf_list, T_S_profile, \n",
    "                                                         geometry_info_2D, geometry_info_1D, isf_stack_mask, \n",
    "                                                         mparam, gamma, C=C, angle_option='local',\n",
    "                                                         box_charac_2D=box_charac_all_2D, box_charac_1D=box_charac_all_1D, box_tot=nD_config, \n",
    "                                                         box_tot_option='nD_config', pism_version=pism_version, picop_opt='no',\n",
    "                                                         verbose=True)  \n",
    "\n",
    "eval_1D.to_netcdf(outputpath_melt+'eval_metrics_1D_'+mparam+'_'+scenario+'_oneFRIS.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f646614b-5647-4f35-9108-4179e97a6f80",
   "metadata": {},
   "source": [
    "RUN AS A LOOP OVER MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da0845e-bbaf-4171-86ad-26164046e8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = 'ssp585'\n",
    "\n",
    "\n",
    "for mod in ['ACCESS-CM2','ACCESS-ESM1-5','CESM2','CESM2-WACCM','CNRM-CM6-1','CNRM-ESM2-1',\n",
    "           'CanESM5','GFDL-CM4','GFDL-ESM4','GISS-E2-1-H','IPSL-CM6A-LR','MPI-ESM1-2-HR',\n",
    "           'MRI-ESM2-0','UKESM1-0-LL']: #\n",
    "    print(mod)\n",
    "    \n",
    "    if mod in ['CNRM-CM6-1','CNRM-ESM2-1']:\n",
    "        to2300 = False\n",
    "    elif mod in ['GISS-E2-1-H']:\n",
    "        to2300 = True\n",
    "    elif mod in ['ACCESS-CM2','ACCESS-ESM1-5','CESM2-WACCM','CanESM5','IPSL-CM6A-LR','MRI-ESM2-0']:\n",
    "        to2300 = True\n",
    "    elif mod in ['MPI-ESM1-2-HR','GFDL-CM4','GFDL-ESM4']:\n",
    "        to2300 = False\n",
    "    elif mod == 'UKESM1-0-LL':\n",
    "        to2300 = True     \n",
    "    elif mod == 'CESM2':\n",
    "        to2300 = False        \n",
    "\n",
    "    if scenario == 'historical':\n",
    "        yystart = 1980 #1850\n",
    "        yyend = 2014\n",
    "    else:\n",
    "        if to2300:\n",
    "            yystart = 2015\n",
    "            yyend = 2300\n",
    "        else:\n",
    "            yystart = 2015\n",
    "            yyend = 2100   \n",
    "\n",
    "    ### READ IN DATA\n",
    "    inputpath_data=home_path+'/DATA/SUMMER_PAPER/interim/'\n",
    "    inputpath_mask = home_path+'/DATA/SUMMER_PAPER/interim/ANTARCTICA_IS_MASKS/BedMachine_4km/'\n",
    "    inputpath_profiles = home_path+'/DATA/SUMMER_PAPER/interim/T_S_PROF/CMIP/'+mod+'/'\n",
    "    inputpath_plumes = home_path+'/DATA/SUMMER_PAPER/interim/PLUMES/BedMachine_4km/'\n",
    "    inputpath_boxes = home_path+'/DATA/SUMMER_PAPER/interim/BOXES/BedMachine_4km/'\n",
    "\n",
    "    outputpath_simple_all_old = home_path+'/DATA/BASAL_MELT_PARAM/interim/SIMPLE/nemo_5km_06161821_oneFRIS/'\n",
    "    outputpath_simple_all_new = home_path+'/DATA/SUMMER_PAPER/interim/SIMPLE/nemo_5km_orig_christoph_oneFRIS/'\n",
    "    outputpath_melt = home_path+'/DATA/SUMMER_PAPER/processed/OCEAN_MELT_RATE_CMIP/'+mod+'/'\n",
    "\n",
    "\n",
    "    # make the domain a little smaller to make the computation even more efficient - file isf has already been made smaller at its creation\n",
    "    map_lim = [-3000000,3000000]\n",
    "\n",
    "    file_isf_orig = xr.open_dataset(inputpath_mask+'BedMachinev2_4km_isf_masks_and_info_and_distance_oneFRIS.nc')\n",
    "    nonnan_Nisf = file_isf_orig['Nisf'].where(np.isfinite(file_isf_orig['front_bot_depth_max']), drop=True).astype(int)\n",
    "    file_isf_nonnan = file_isf_orig.sel(Nisf=nonnan_Nisf)\n",
    "    rignot_isf = file_isf_nonnan.Nisf.where(np.isfinite(file_isf_nonnan['isf_area_rignot']), drop=True)\n",
    "    file_isf = file_isf_nonnan.sel(Nisf=rignot_isf)\n",
    "    file_isf['isf_name'] = file_isf['isf_name'].astype(str)\n",
    "    file_isf['region'] = file_isf['region'].astype(str)\n",
    "\n",
    "    BedMachine_orig = xr.open_dataset(inputpath_data+'BedMachine_v2_aggregated4km_allvars.nc')\n",
    "    BedMachine_orig_cut = uf.cut_domain_stereo(BedMachine_orig, map_lim, map_lim)\n",
    "    file_draft = (BedMachine_orig_cut['thickness'] - BedMachine_orig_cut['surface']).where(file_isf['ISF_mask'] > 1)\n",
    "    file_isf_conc = BedMachine_orig_cut['isf_conc']\n",
    "\n",
    "    file_TS_list = []\n",
    "    for tt in tqdm(range(yystart,yyend+1)):\n",
    "        file_T_orig = xr.open_dataset(inputpath_profiles+'T_mean_prof_50km_contshelf_'+mod+'_'+scenario+'_'+str(tt)+'.nc')\n",
    "        file_S_orig = xr.open_dataset(inputpath_profiles+'S_mean_prof_50km_contshelf_'+mod+'_'+scenario+'_'+str(tt)+'.nc')\n",
    "        file_TS_orig = xr.merge([file_T_orig.rename({'thetao':'theta_ocean'}), file_S_orig.rename({'so':'salinity_ocean'})]).sel(Nisf=rignot_isf).assign_coords({'time': tt})\n",
    "        file_TS_list.append(file_TS_orig)\n",
    "    file_TS = xr.concat(file_TS_list, dim='time').rename({'z':'depth'})\n",
    "    file_TS['depth'] = -1*file_TS['depth']\n",
    "    \n",
    "    depth_axis_old = file_TS.depth.values\n",
    "    depth_axis_new = np.concatenate((np.zeros(1),depth_axis_old))\n",
    "    file_TS_with_shallow = file_TS.interp({'depth': depth_axis_new})\n",
    "\n",
    "    grid_cell_area_file = xr.open_dataset(inputpath_data+'gridarea_ISMIP6_AIS_4000m_grid.nc').sel(x=file_isf.x,y=file_isf.y)\n",
    "    true_grid_cell_area = grid_cell_area_file['cell_area'].drop('lon').drop('lat')\n",
    "    cell_area_weight = true_grid_cell_area/(4000 * 4000)\n",
    "\n",
    "    lon = file_isf.longitude\n",
    "    lat = file_isf.latitude\n",
    "\n",
    "    xx = file_isf.x\n",
    "    yy = file_isf.y\n",
    "    dx = (xx[2] - xx[1]).values\n",
    "    dy = (yy[2] - yy[1]).values\n",
    "    grid_cell_area_const = abs(dx*dy)  \n",
    "    grid_cell_area_weighted = file_isf_conc * grid_cell_area_const * cell_area_weight\n",
    "\n",
    "    ice_draft_pos = file_draft\n",
    "    ice_draft_neg = -ice_draft_pos\n",
    "\n",
    "    isf_stack_mask = uf.create_stacked_mask(file_isf['ISF_mask'], file_isf.Nisf, ['y','x'], 'mask_coord')\n",
    "\n",
    "    box_charac_all_2D = xr.open_dataset(inputpath_boxes + 'BedMachine_4km_boxes_2D_oneFRIS.nc')\n",
    "    box_charac_all_1D = xr.open_dataset(inputpath_boxes + 'BedMachine_4km_boxes_1D_oneFRIS.nc')\n",
    "    plume_charac = xr.open_dataset(inputpath_plumes+'BedMachine_4km_plume_characteristics.nc')\n",
    "\n",
    "    param_var_of_int_2D = file_isf[['ISF_mask', 'latitude', 'longitude', 'dGL']]\n",
    "    param_var_of_int_1D = file_isf[['front_bot_depth_avg', 'front_bot_depth_max','isf_name']]\n",
    "\n",
    "    geometry_info_2D = plume_charac.merge(param_var_of_int_2D).merge(ice_draft_pos.rename('ice_draft_pos')).merge(grid_cell_area_weighted.rename('grid_cell_area_weighted')).merge(file_isf_conc.rename('isfdraft_conc'))\n",
    "    geometry_info_1D = param_var_of_int_1D       \n",
    "\n",
    "    ### RUN PARAMS\n",
    "    nisf_list_orig = geometry_info_1D.Nisf\n",
    "    T_S_profile = file_TS_with_shallow.ffill(dim='depth').bfill(dim='depth')\n",
    "\n",
    "    gammas_new_tuning = xr.open_dataset(outputpath_simple_all_new + 'gammas_simple_ALL.nc')\n",
    "    gammas_old_tuning = xr.open_dataset(outputpath_simple_all_old + 'gammas_simple_ALL.nc')\n",
    "    gammas_SMALL_tuning = xr.open_dataset(outputpath_simple_all_new + 'gammas_simple_SMALL.nc')\n",
    "    gammas_LARGE_tuning = xr.open_dataset(outputpath_simple_all_new + 'gammas_simple_LARGE.nc')\n",
    "\n",
    "    simple_param_types = ['linear_local', 'quadratic_local', 'quadratic_local_locslope',\n",
    "                          'quadratic_mixed_mean', 'quadratic_mixed_locslope'] \n",
    "\n",
    "    nisf_list_orig = geometry_info_1D.Nisf\n",
    "    T_S_profile = file_TS_with_shallow.ffill(dim='depth').bfill(dim='depth')\n",
    "\n",
    "\n",
    "    for mparam in simple_param_types:\n",
    "        \n",
    "        print(mparam)\n",
    "        eval_1D_list = []\n",
    "        for tuning_sort in ['LARGE','SMALL']: #'old'\n",
    "\n",
    "            if tuning_sort == 'LARGE':\n",
    "                nisf_list = nisf_list_orig.sel(Nisf=[10,11])\n",
    "                gamma = gammas_LARGE_tuning['slope'].sel(param=mparam)\n",
    "            elif tuning_sort == 'SMALL':\n",
    "                nisf_list = nisf_list_orig.drop_sel(Nisf=[10,11])\n",
    "                gamma = gammas_LARGE_tuning['slope'].sel(param=mparam)\n",
    "\n",
    "            eval_1D = meltf.calculate_melt_rate_Gt_and_box1_all_isf(nisf_list, T_S_profile, \n",
    "                                                                    geometry_info_2D, geometry_info_1D, isf_stack_mask, \n",
    "                                                                    mparam, gamma, U_param=True, \n",
    "                                                                    box_charac_2D=box_charac_all_2D, box_charac_1D=box_charac_all_1D, verbose=False)\n",
    "            eval_1D_list.append(eval_1D)\n",
    "\n",
    "        eval_1D_all = xr.concat(eval_1D_list,dim='Nisf')\n",
    "\n",
    "        eval_1D_all.to_netcdf(outputpath_melt+'eval_metrics_1D_'+mparam+'_'+scenario+'_oneFRIS.nc')\n",
    "\n",
    "\n",
    "    #########\n",
    "\n",
    "    mparam = 'lazero19'   \n",
    "    print(mparam)\n",
    "\n",
    "    nisf_list = nisf_list_orig\n",
    "    gamma = 6.2e-4\n",
    "    E0 = 2.0e-2\n",
    "\n",
    "\n",
    "\n",
    "    eval_1D = meltf.calculate_melt_rate_Gt_and_box1_all_isf(nisf_list, T_S_profile, \n",
    "                                                     geometry_info_2D, geometry_info_1D, isf_stack_mask, \n",
    "                                                     mparam, gamma, E0=E0, \n",
    "                                                     box_charac_2D=box_charac_all_2D, box_charac_1D=box_charac_all_1D, verbose=False)\n",
    "\n",
    "\n",
    "\n",
    "    eval_1D.to_netcdf(outputpath_melt+'eval_metrics_1D_'+mparam+'_'+scenario+'_oneFRIS.nc')\n",
    "\n",
    "    #########\n",
    "\n",
    "    nisf_list_orig = geometry_info_1D.Nisf\n",
    "    T_S_profile = file_TS_with_shallow.ffill(dim='depth').bfill(dim='depth')\n",
    "\n",
    "    mparam = 'boxes_4_pismyes_picopno'\n",
    "    print(mparam)\n",
    "    pism_version = 'yes'\n",
    "    nD_config = 4\n",
    "\n",
    "\n",
    "    nisf_list = nisf_list_orig\n",
    "    gamma = 0.87e-5\n",
    "    C = 2.8e6\n",
    "\n",
    "    eval_1D = meltf.calculate_melt_rate_Gt_and_box1_all_isf(nisf_list, T_S_profile, \n",
    "                                                             geometry_info_2D, geometry_info_1D, isf_stack_mask, \n",
    "                                                             mparam, gamma, C=C, angle_option='local',\n",
    "                                                             box_charac_2D=box_charac_all_2D, box_charac_1D=box_charac_all_1D, box_tot=nD_config, \n",
    "                                                             box_tot_option='nD_config', pism_version=pism_version, picop_opt='no',\n",
    "                                                             verbose=False)  \n",
    "\n",
    "    eval_1D.to_netcdf(outputpath_melt+'eval_metrics_1D_'+mparam+'_'+scenario+'_oneFRIS.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fad820-e361-45db-9b9b-40428c9a77a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
