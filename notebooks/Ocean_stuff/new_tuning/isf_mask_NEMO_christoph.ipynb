{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Fri Feb 15 11:43 2021\n",
    "\n",
    "use script to identify ice shelves in NEMO data from Christoph\n",
    "=> updated to use the corrected ice shelf draft and the ice shelf concentration\n",
    "# to be used from now on! (at least for non-huge data)\n",
    "\n",
    "@author: Clara Burgard\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "from pyproj import Transformer\n",
    "#from matplotlib import cm\n",
    "#import cartopy\n",
    "#import cartopy.crs as ccrs\n",
    "#import matplotlib as mpl\n",
    "import pandas as pd\n",
    "from tqdm.notebook import trange, tqdm\n",
    "#from tqdm import tqdm\n",
    "import multimelt.plume_functions as pf\n",
    "import basal_melt_param.box_functions as bf\n",
    "import basal_melt_param.useful_functions as uf\n",
    "import multimelt.create_isf_mask_functions as isfmf\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_lim = [-3000000,3000000]\n",
    "\n",
    "#chunk_size = 700\n",
    "chunk_size = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nemo_run = 'isfru94' # 'isf94','isfru94','ctrl94'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "###### READ IN DATA\n",
    "######\n",
    "\n",
    "\n",
    "#if run on luke\n",
    "inputpath_data='/bettik/burgardc/DATA/SUMMER_PAPER/interim/NEMO_'+nemo_run+'_ANT_STEREO/'\n",
    "inputpath_metadata='/bettik/burgardc/SCRIPTS/basal_melt_param/data/raw/MASK_METADATA/'\n",
    "outputpath_mask='/bettik/burgardc/DATA/SUMMER_PAPER/interim/ANTARCTICA_IS_MASKS/nemo_5km_'+nemo_run+'/'\n",
    "outputpath_boxes = '/bettik/burgardc/DATA/SUMMER_PAPER/interim/BOXES/nemo_5km_'+nemo_run+'/'\n",
    "outputpath_plumes = '/bettik/burgardc/DATA/SUMMER_PAPER/interim/PLUMES/nemo_5km_'+nemo_run+'/'\n",
    "\n",
    "\n",
    "#ds_nemo = xr.open_dataset(outputpath_mask_orig+'nemo_5km_isf_masks_and_info_and_distance.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Create the masks for ice shelves/ground/pinning points/grounding line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "WITH FIXED GEOMETRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_mask_orig = xr.open_dataset(inputpath_data+'other_mask_vars_Ant_stereo.nc')\n",
    "file_mask_orig_cut = uf.cut_domain_stereo(file_mask_orig, map_lim, map_lim)\n",
    "file_mask = xr.open_dataset(inputpath_data+'custom_lsmask_Ant_stereo_clean.nc')#, chunks={'x': chunk_size, 'y': chunk_size})\n",
    "file_mask_cut = uf.cut_domain_stereo(file_mask, map_lim, map_lim)\n",
    "file_other = xr.open_dataset(inputpath_data+'corrected_draft_bathy_isf.nc')#, chunks={'x': chunk_size, 'y': chunk_size})\n",
    "file_other_cut = uf.cut_domain_stereo(file_other, map_lim, map_lim)\n",
    "file_conc = xr.open_dataset(inputpath_data+'isfdraft_conc_Ant_stereo.nc')\n",
    "file_conc_cut = uf.cut_domain_stereo(file_conc, map_lim, map_lim)\n",
    "\n",
    "#file_TS_orig = xr.open_dataset(inputpath_data + '3D_variables_of_interest_allyy_Ant_stereo_'+str(timet.values.astype(int))+'.nc').isel(time=0).drop('time')\n",
    "#file_TS_cut = uf.cut_domain_stereo(file_TS_orig, map_lim, map_lim)\n",
    "\n",
    "file_bed_orig = file_mask_orig_cut['bathy_metry']\n",
    "file_draft = file_other_cut['corrected_isfdraft']\n",
    "file_msk = file_mask_cut['ls_mask012']#.where((file_TS_cut['so'].max('deptht') > 0), 2).drop('time') #0 = ocean, 1 = ice shelves, 2 = grounded ice\n",
    "file_isf_conc = file_conc_cut['isfdraft_conc']\n",
    "\n",
    "xx = file_mask_cut['x']\n",
    "yy = file_mask_cut['y']\n",
    "\n",
    "whole_ds_tt = isfmf.create_mask_and_metadata_isf(file_msk, -1*file_bed_orig, file_msk, -1*file_draft, file_isf_conc, False, \n",
    "                                          inputpath_metadata+'lonlat_masks.txt', outputpath_mask, \n",
    "                                          inputpath_metadata + 'iceshelves_metadata_Nico.txt', \n",
    "                                          inputpath_metadata+'GL_flux_rignot13.csv', mouginot_basins=False, variable_geometry=False,\n",
    "                                          write_ismask = 'yes', write_groundmask = 'yes', write_outfile='yes',\n",
    "                                          ground_point ='no',dist=40, add_fac=120, connectivity=4, threshold=4,\n",
    "                                          write_metadata='yes')\n",
    "\n",
    "print('------- WRITE TO NETCDF -----------')\n",
    "whole_ds_tt.to_netcdf(outputpath_mask + 'nemo_5km_isf_masks_and_info_and_distance_oneFRIS.nc','w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Prepare the box characteristics (writes the output directly to files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_mask_orig = xr.open_dataset(inputpath_data+'other_mask_vars_Ant_stereo.nc')\n",
    "file_mask_orig_cut = uf.cut_domain_stereo(file_mask_orig, map_lim, map_lim)\n",
    "file_mask = xr.open_dataset(inputpath_data+'custom_lsmask_Ant_stereo_clean.nc')#, chunks={'x': chunk_size, 'y': chunk_size})\n",
    "file_mask_cut = uf.cut_domain_stereo(file_mask, map_lim, map_lim)\n",
    "file_other = xr.open_dataset(inputpath_data+'corrected_draft_bathy_isf.nc')#, chunks={'x': chunk_size, 'y': chunk_size})\n",
    "file_other_cut = uf.cut_domain_stereo(file_other, map_lim, map_lim)\n",
    "file_conc = xr.open_dataset(inputpath_data+'isfdraft_conc_Ant_stereo.nc')\n",
    "file_conc_cut = uf.cut_domain_stereo(file_conc, map_lim, map_lim)          \n",
    "\n",
    "file_bed_orig = file_mask_orig_cut['bathy_metry']\n",
    "file_draft = file_other_cut['corrected_isfdraft']\n",
    "file_msk = file_mask_cut['ls_mask012']#.where((file_TS_cut['so'].max('deptht') > 0), 2).drop('time') #0 = ocean, 1 = ice shelves, 2 = grounded ice\n",
    "file_isf_conc = file_conc_cut['isfdraft_conc']\n",
    "\n",
    "xx = file_mask_cut['x']\n",
    "yy = file_mask_cut['y']\n",
    "\n",
    "whole_ds_tt = xr.open_dataset(outputpath_mask + 'nemo_5km_isf_masks_and_info_and_distance_oneFRIS.nc')\n",
    "\n",
    "nonnan_Nisf = whole_ds_tt['Nisf'].where(np.isfinite(whole_ds_tt['front_bot_depth_max']), drop=True).astype(int)\n",
    "file_isf_nonnan = whole_ds_tt.sel(Nisf=nonnan_Nisf)\n",
    "large_isf = file_isf_nonnan['Nisf'].where(file_isf_nonnan['isf_area_here'] >= 2500, drop=True)\n",
    "file_isf = file_isf_nonnan.sel(Nisf=large_isf)\n",
    "if 'labels' in file_isf.coords.keys():\n",
    "    file_isf = file_isf.drop('labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "isf_var_of_int = whole_ds_tt[['ISF_mask', 'GL_mask', 'dGL', 'dIF', 'latitude', 'longitude', 'isf_name']]\n",
    "out_2D, out_1D = bf.box_charac_file(file_isf['Nisf'],isf_var_of_int, -1*file_draft, file_isf_conc, outputpath_boxes, max_nb_box=10)\n",
    "out_2D.to_netcdf(outputpath_boxes + 'nemo_5km_boxes_2D_oneFRIS.nc')\n",
    "out_1D.to_netcdf(outputpath_boxes + 'nemo_5km_boxes_1D_oneFRIS.nc')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "box_1D = xr.open_dataset(outputpath_boxes + 'nemo_5km_boxes_1D_oneFRIS_1970.nc')\n",
    "box_2D = xr.open_dataset(outputpath_boxes + 'nemo_5km_boxes_2D_oneFRIS_1970.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "isf_var_of_int = whole_ds[['ISF_mask', 'GL_mask', 'dGL', 'dIF', 'latitude', 'longitude', 'isf_name']]\n",
    "out_2D, out_1D = bf.box_charac_file(file_isf['Nisf'],isf_var_of_int, -1*file_draft, file_isf_conc, outputpath_boxes, max_nb_box=10)\n",
    "#out_2D.to_netcdf(outputpath_boxes + 'nemo_5km_boxes_2D.nc') # separated Filchner and Ronne (before review)\n",
    "#out_1D.to_netcdf(outputpath_boxes + 'nemo_5km_boxes_1D.nc') # separated Filchner and Ronne (before review)\n",
    "out_2D.to_netcdf(outputpath_boxes + 'nemo_5km_boxes_2D_oneFRIS.nc')\n",
    "out_1D.to_netcdf(outputpath_boxes + 'nemo_5km_boxes_1D_oneFRIS.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "Prepare the plume characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "plume_param_options = ['simple','lazero', 'appenB']\n",
    "\n",
    "file_other = xr.open_dataset(inputpath_data+'corrected_draft_bathy_isf.nc')#, chunks={'x': chunk_size, 'y': chunk_size})\n",
    "file_other_cut = uf.cut_domain_stereo(file_other, map_lim, map_lim)\n",
    "\n",
    "file_draft = file_other_cut['corrected_isfdraft']\n",
    "\n",
    "xx = file_mask_cut['x']\n",
    "yy = file_mask_cut['y']\n",
    "\n",
    "whole_ds_tt = xr.open_dataset(outputpath_mask + 'nemo_5km_isf_masks_and_info_and_distance_oneFRIS.nc')\n",
    "\n",
    "nonnan_Nisf = whole_ds_tt['Nisf'].where(np.isfinite(whole_ds_tt['front_bot_depth_max']), drop=True).astype(int)\n",
    "file_isf_nonnan = whole_ds_tt.sel(Nisf=nonnan_Nisf)\n",
    "large_isf = file_isf_nonnan['Nisf'].where(file_isf_nonnan['isf_area_here'] >= 2500, drop=True)\n",
    "file_isf = file_isf_nonnan.sel(Nisf=large_isf)\n",
    "if 'labels' in file_isf.coords.keys():\n",
    "    file_isf = file_isf.drop('labels')\n",
    "\n",
    "plume_var_of_int = file_isf[['ISF_mask', 'GL_mask', 'IF_mask', 'dIF', 'dGL_dIF', 'latitude', 'longitude', 'front_ice_depth_avg']]\n",
    "\n",
    "# Compute the ice draft\n",
    "ice_draft_pos = file_draft\n",
    "# Be careful with ice shelf 178 and 195 - they have a negative ice draft\n",
    "# I don't know how to fix it at the moment so I put it to nan\n",
    "#ice_draft_pos = ice_draft_pos.where(plume_var_of_int['ISF_mask'] != 178, np.nan)\n",
    "#ice_draft_pos = ice_draft_pos.where(plume_var_of_int['ISF_mask'] != 195, np.nan)\n",
    "\n",
    "ice_draft_neg = -1*ice_draft_pos\n",
    "\n",
    "\n",
    "plume_charac = pf.prepare_plume_charac(plume_param_options, ice_draft_pos, plume_var_of_int)\n",
    "print('------ WRITE TO NETCDF -------')\n",
    "#plume_charac.to_netcdf(outputpath_plumes+'nemo_5km_plume_characteristics.nc')\n",
    "plume_charac.to_netcdf(outputpath_plumes+'nemo_5km_plume_characteristics_oneFRIS.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "plume_param_options = ['new_lazero'] #'cavity',, 'local','lazero'\n",
    "\n",
    "plume_var_of_int = file_isf[['ISF_mask', 'GL_mask', 'IF_mask', 'dIF', 'dGL_dIF', 'latitude', 'longitude', 'front_ice_depth_avg']]\n",
    "\n",
    "# Compute the ice draft\n",
    "ice_draft_pos = file_draft\n",
    "# Be careful with ice shelf 178 and 195 - they have a negative ice draft\n",
    "# I don't know how to fix it at the moment so I put it to nan\n",
    "#ice_draft_pos = ice_draft_pos.where(plume_var_of_int['ISF_mask'] != 178, np.nan)\n",
    "#ice_draft_pos = ice_draft_pos.where(plume_var_of_int['ISF_mask'] != 195, np.nan)\n",
    "\n",
    "ice_draft_neg = -1*ice_draft_pos\n",
    "\n",
    "plume_charac_shift2 = pf.prepare_plume_charac(plume_param_options, ice_draft_pos, plume_var_of_int, grad_corr=5, dir_nb=16, extra_shift=2, dist_incl=1)\n",
    "plume_charac_shift1 = pf.prepare_plume_charac(plume_param_options, ice_draft_pos, plume_var_of_int, grad_corr=5, dir_nb=16, extra_shift=1, dist_incl=1)\n",
    "plume_charac = plume_charac_shift2.combine_first(plume_charac_shift1)\n",
    "print('------ WRITE TO NETCDF -------')\n",
    "plume_charac.to_netcdf(outputpath_plumes+'nemo_5km_plume_characteristics_oneFRIS_lazero_comparison.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "plume_charac_old = xr.open_dataset(outputpath_plumes+'nemo_5km_plume_characteristics_oneFRIS.nc')\n",
    "plume_charac_new = xr.open_dataset(outputpath_plumes+'nemo_5km_plume_characteristics_oneFRIS_lazero_comparison.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "((plume_charac_old['alpha'].sel(option='lazero') == 0) & (file_isf['ISF_mask'] == 42)).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "((np.isnan(plume_charac_new['zGL'].sel(option='new_lazero'))) & (file_isf['ISF_mask'] == 42)).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plume_charac_new['zGL'].sel(option='new_lazero').plot() #.where(file_isf['ISF_mask'] == 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "FILL POINTS WHERE SLOPE IS NOT INCLINED TOWARDS GROUNDING LINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "plume_charac = xr.open_dataset(outputpath_plumes+'nemo_5km_plume_characteristics_oneFRIS.nc')\n",
    "plume_charac = plume_charac.sel(y=plume_charac.y[::-1])\n",
    "\n",
    "file_isf_new = file_isf.sel(y=file_isf.y[::-1])\n",
    "\n",
    "alpha_all_corrected = plume_charac['alpha'].sel(option='lazero') * np.nan\n",
    "zGL_all_corrected = plume_charac['zGL'].sel(option='lazero') * np.nan\n",
    "\n",
    "\n",
    "for kisf in tqdm(file_isf.Nisf):\n",
    "    alpha_kisf_lazero = plume_charac['alpha'].sel(option='lazero').where(file_isf_new['ISF_mask']==kisf, drop=True).drop('Nisf')\n",
    "    alpha_kisf_local = plume_charac['alpha'].sel(option='appenB').where(file_isf_new['ISF_mask']==kisf, drop=True).drop('Nisf')\n",
    "    alpha_kisf_lazero_corrected = alpha_kisf_lazero.where(alpha_kisf_lazero > 0, alpha_kisf_local)\n",
    "\n",
    "    zGL_kisf_lazero = plume_charac['zGL'].sel(option='lazero').where(file_isf_new['ISF_mask']==kisf, drop=True).drop('Nisf')\n",
    "    zGL_kisf_local = plume_charac['zGL'].sel(option='appenB').where(file_isf_new['ISF_mask']==kisf, drop=True).drop('Nisf')\n",
    "\n",
    "    zGL_kisf_lazero_fillx = zGL_kisf_lazero.where(alpha_kisf_lazero != 0).interpolate_na(dim='x',method='nearest')\n",
    "    zGL_kisf_lazero_filly = zGL_kisf_lazero.where(alpha_kisf_lazero != 0).interpolate_na(dim='y',method='nearest')\n",
    "    zGL_kisf_lazero_maxboth = xr.concat([zGL_kisf_lazero_fillx,zGL_kisf_lazero_filly],dim='dim0').max('dim0')\n",
    "    #zGL_kisf_lazero_999_minboth = xr.concat([zGL_kisf_lazero_999_fillx,zGL_kisf_lazero_999_filly],dim='dim0').mean('dim0')\n",
    "    zGL_kisf_lazero_corrected = zGL_kisf_lazero_maxboth.where(np.isfinite(zGL_kisf_lazero))\n",
    "    \n",
    "    alpha_all_corrected = alpha_all_corrected.where(file_isf_new['ISF_mask']!=kisf, alpha_kisf_lazero_corrected.reindex_like(alpha_all_corrected))\n",
    "    zGL_all_corrected = zGL_all_corrected.where(file_isf_new['ISF_mask']!=kisf, zGL_kisf_lazero_corrected.reindex_like(alpha_all_corrected))\n",
    "alpha_all_corrected = alpha_all_corrected.where(np.isfinite(alpha_all_corrected), 0).drop('Nisf')\n",
    "zGL_all_corrected = zGL_all_corrected.where(np.isfinite(alpha_all_corrected), 0).drop('Nisf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "plume_charac['alpha'] = xr.concat([plume_charac['alpha'].sel(option='simple'),alpha_all_corrected,plume_charac['alpha'].sel(option='appenB')], dim='option', coords='minimal').sel(y=plume_charac.y[::-1])\n",
    "plume_charac['zGL'] = xr.concat([plume_charac['zGL'].sel(option='simple'),zGL_all_corrected,plume_charac['zGL'].sel(option='appenB')], dim='option', coords='minimal').sel(y=plume_charac.y[::-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------ WRITE TO NETCDF -------')\n",
    "plume_charac.to_netcdf(outputpath_plumes+'nemo_5km_plume_characteristics_oneFRIS_corrected.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "Prepare correct bathymetry (accounting for ice shelf concentration but also if we are at ice front or grounding line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_ds = xr.open_dataset(outputpath_mask + 'nemo_5km_isf_masks_and_info_and_distance_oneFRIS.nc')\n",
    "\n",
    "file_bed_orig = file_mask_orig_cut['bathy_metry']\n",
    "file_bed_corr = file_other_cut['corrected_isf_bathy']\n",
    "file_draft = file_other_cut['corrected_isfdraft'] \n",
    "\n",
    "file_bed_goodGL = file_bed_orig.where(file_draft < file_bed_orig,file_bed_corr)\n",
    "file_bed_goodGL_with_ocean =  file_bed_goodGL.where(whole_ds['ISF_mask'] > 1, file_bed_orig)\n",
    "file_bed_goodGL_with_ocean.to_dataset(name='bathymetry').to_netcdf(outputpath_mask + 'processed_bathymetry.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "CHECK RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_2D_boxes = xr.open_dataset(outputpath_boxes + 'nemo_5km_boxes_2D_oneFRIS.nc')\n",
    "out_1D_boxes = xr.open_dataset(outputpath_boxes + 'nemo_5km_boxes_1D_oneFRIS.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_2D_boxes['box_location'].sel(box_nb_tot=out_1D_boxes['nD_config'].sel(config=4,Nisf=75)).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_ds = xr.open_dataset(outputpath_mask + 'nemo_5km_isf_masks_and_info_and_distance_new_oneFRIS.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonnan_Nisf = whole_ds['Nisf'].where(np.isfinite(whole_ds['front_bot_depth_max']), drop=True).astype(int)\n",
    "file_isf_nonnan = whole_ds.sel(Nisf=nonnan_Nisf)\n",
    "large_isf = file_isf_nonnan['Nisf'].where(file_isf_nonnan['isf_area_here'] >= 2500, drop=True)\n",
    "file_isf = file_isf_nonnan.sel(Nisf=large_isf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "isf_mask = file_isf['ISF_mask'].where(file_isf['ISF_mask'] == file_isf.Nisf).sum('Nisf')\n",
    "isf_mask = isf_mask.where(isf_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "GL_flux = file_isf['GL_flux']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "GL_flux_new = GL_flux.where(isf_mask==file_isf.Nisf).sum('Nisf')\n",
    "GL_flux_new = GL_flux_new.where(GL_flux_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "GL_flux_new.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "nisf_list = whole_ds.Nisf.values.tolist()\n",
    "nisf_list.remove(11)\n",
    "nisf_list.remove(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "nisf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_ds = xr.open_dataset(outputpath_mask + 'nemo_5km_isf_masks_and_info_and_distance_new.nc')\n",
    "plume_charac = xr.open_dataset(outputpath_plumes+'nemo_5km_plume_characteristics.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "plume_charac['alpha'].sel(option='simple').where(whole_ds['ISF_mask']==75,drop=True).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_draft_pos.where(whole_ds['ISF_mask']==75, drop=True).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "plume_var_of_int['GL_mask'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "plume_var_of_int['GL_mask'].where(plume_var_of_int['GL_mask']==75, drop=True).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_ds['ISF_mask'].where(whole_ds['ISF_mask']==0).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = region_isf.x[1] - region_isf.x[0]\n",
    "dy = region_isf.y[1] - region_isf.y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_isf = whole_ds['ISF_mask'].where(whole_ds['ISF_mask']==75, drop=True)\n",
    "region_x = np.arange(region_isf.x.min() - 2*dx, region_isf.x.max() + 2.5*dx, dx)\n",
    "region_y = np.arange(region_isf.y.max() - 2*dy, region_isf.y.min() + 2.5*dy, dy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_to_look_at = whole_ds['ISF_mask'].sel(x=region_x,y=region_y)\n",
    "mask_ground = region_to_look_at.where(region_to_look_at != 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_10 = mask_ground.where(mask_ground==2, 0) * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_10.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_neighbors = np.array(([0, 1, 0], [1, 1, 1], [0, 1, 0]))\n",
    "xr_weights = xr.DataArray(data=weights_neighbors, dims=['y', 'x'])\n",
    "\n",
    "xr_corr_neighbors = mask_10.copy(data=pf.nd_corr(mask_10,xr_weights))\n",
    "\n",
    "cut_gline = xr_corr_neighbors.where((region_to_look_at>1) & (xr_corr_neighbors>0))\n",
    "mask_gline = region_to_look_at.where(cut_gline>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_gline.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "region_to_look_at.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_ds['ISF_mask'].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "whole_ds['ISF_mask'].sel(x=np.arange(-2998000.,0.5,dx),y=np.arange(2998000.,0,dy)).plot(vmax=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_fac=150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_gline_orig = whole_ds['GL_mask']\n",
    "\n",
    "###################\n",
    "\n",
    "larger_region = whole_ds['ISF_mask'].sel(x=np.arange(-2998000.,0.5,dx),y=np.arange(2998000.,0,dy))\n",
    "mask_10_first = larger_region.where(larger_region == 0, 5).where(larger_region != 0, 1)\n",
    "mask_gnd = mask_10_first.where(mask_10_first == 1, 0) #set all ice shelves and open ocean to 0, set all grounded ice to 1\n",
    "\n",
    "meshx_gnd, meshy_gnd = np.meshgrid(mask_gnd.x,mask_gnd.y)\n",
    "meshx_gnd_da = mask_gnd.copy(data=meshx_gnd)\n",
    "meshy_gnd_da = mask_gnd.copy(data=meshy_gnd)\n",
    "\n",
    "core = mask_gnd.sel(x=np.arange(-1938000.,-1900000., dx),y=np.arange(718000.,680000., dy)).reindex_like(mask_gnd)\n",
    "mask_core = mask_gnd.where(np.isnan(core),5)\n",
    "\n",
    "# filter that checks the point around\n",
    "weights_filter = np.zeros((3,3))\n",
    "weights_filter[0,1] = 1\n",
    "weights_filter[1,0] = 1\n",
    "weights_filter[1,2] = 1\n",
    "weights_filter[2,1] = 1\n",
    "\n",
    "weights_da = xr.DataArray(data=weights_filter,dims=['y0','x0'])\n",
    "\n",
    "iter_mask = mask_core.copy()\n",
    "for n in tqdm(range(add_fac)):\n",
    "    corr = pf.xr_nd_corr_v2(iter_mask, weights_filter)\n",
    "    iter_mask = iter_mask.where(~((corr >= 5) & (mask_core == 1)),5)\n",
    "\n",
    "mask_ground = iter_mask.where(iter_mask !=5, 2)#.reindex_like(la)\n",
    "mask_ground = mask_ground.where(mask_ground>0,0)\n",
    "\n",
    "##########################################\n",
    "\n",
    "mask_10 = mask_ground.where(mask_ground==2, 0) * 0.5\n",
    "weights_neighbors = np.array(([0, 1, 0], [1, 1, 1], [0, 1, 0]))\n",
    "xr_weights = xr.DataArray(data=weights_neighbors, dims=['y', 'x'])\n",
    "\n",
    "xr_corr_neighbors = mask_10.copy(data=pf.nd_corr(mask_10,xr_weights))\n",
    "\n",
    "cut_gline = xr_corr_neighbors.where((larger_region>1) & (xr_corr_neighbors>0))\n",
    "mask_gline = larger_region.where(cut_gline>0).reindex_like(mask_gline_orig)\n",
    "\n",
    "mask_gline_final = mask_gline_orig.where(mask_gline != 9, mask_gline)\n",
    "mask_gline_final = mask_gline_final.where(mask_gline != 54, mask_gline)\n",
    "mask_gline_final = mask_gline_final.where(mask_gline != 75, mask_gline)\n",
    "mask_gline_final = mask_gline_final.where(mask_gline != 98, mask_gline)\n",
    "mask_gline_final = mask_gline_final.where(mask_gline != 99, mask_gline)\n",
    "mask_gline_final = mask_gline_final.where(mask_gline != 100, mask_gline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_ds['isf_name'].sel(Nisf=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_gline_final.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_ds['ISF_mask'].y.sel(y=720000, method='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_10 = file_msk.where(file_msk == 2, 0).where(file_msk != 2,1) #set all ice shelves and open ocean to 0, set all grounded ice to 1\n",
    "\n",
    "mask_gnd = mask_10.where(mask_10>0, drop=True)\n",
    "mask_gnd = mask_gnd.where(mask_gnd>0,0)\n",
    "\n",
    "meshx_gnd, meshy_gnd = np.meshgrid(mask_gnd.x,mask_gnd.y)\n",
    "meshx_gnd_da = mask_gnd.copy(data=meshx_gnd)\n",
    "meshy_gnd_da = mask_gnd.copy(data=meshy_gnd)\n",
    "\n",
    "\n",
    "max_len_xy = max(len(meshx_gnd_da.x),len(meshx_gnd_da.y))\n",
    "half_range = round(max_len_xy/2)\n",
    "\n",
    "mask_core = mask_gnd.where(~((uf.in_range(meshx_gnd_da, [-2*dist*dx,2*dist*dx]) # assuming that the South Pole is in the center of the projection\n",
    "                      & uf.in_range(meshy_gnd_da, [-2*dist*dy,2*dist*dy]))), 5)\n",
    "\n",
    "# filter that checks the point around\n",
    "weights_filter = np.zeros((3,3))\n",
    "weights_filter[0,1] = 1\n",
    "weights_filter[1,0] = 1\n",
    "weights_filter[1,2] = 1\n",
    "weights_filter[2,1] = 1\n",
    "\n",
    "weights_da = xr.DataArray(data=weights_filter,dims=['y0','x0'])\n",
    "\n",
    "iter_mask = mask_core.copy()\n",
    "for n in tqdm(range(half_range+2*dist+add_fac)):\n",
    "    corr = pf.xr_nd_corr_v2(iter_mask, weights_filter)\n",
    "    iter_mask = iter_mask.where(~((corr >= 5) & (mask_core == 1)),5)\n",
    "\n",
    "mask_ground = iter_mask.where(iter_mask !=5, 2).reindex_like(mask_10)\n",
    "mask_ground = mask_ground.where(mask_ground>0,0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
