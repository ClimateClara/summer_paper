{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Fri Jun 4 15:50 2020\n",
    "\n",
    "This is a script to cut out the T and S in the 50 km in front of the ice front\n",
    "\n",
    "@author: Clara Burgard\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "- calculate the distance to the ice front for the small domain in front of the ice shelf\n",
    "- take the ocean points at distance of ~50 km of the ice front "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm\n",
    "import gsw\n",
    "import matplotlib.pyplot as plt\n",
    "import basal_melt_param.useful_functions as uf\n",
    "import basal_melt_param.T_S_profile_functions as tspf\n",
    "import basal_melt_param.melt_functions as meltf\n",
    "import basal_melt_param.box_functions as bf\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "\n",
    "import itertools\n",
    "\n",
    "import distributed\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = distributed.Client(n_workers=4, dashboard_address=':8796', local_directory='/tmp', memory_limit='6GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "READ IN THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nemo_run = 'isfru94' # 'EPM026','EPM031', 'EPM034'\n",
    "if nemo_run in ['ctrl94']:\n",
    "    yy_start = 1982\n",
    "    yy_end = 2013\n",
    "elif nemo_run in ['isf94','isfru94']:\n",
    "    yy_start = 2014\n",
    "    yy_end = 2100\n",
    "    \n",
    "yy_ex = 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputpath_data='/bettik/burgardc/DATA/SUMMER_PAPER/interim/NEMO_'+nemo_run+'_ANT_STEREO/'\n",
    "inputpath_profiles='/bettik/burgardc/DATA/SUMMER_PAPER/interim/T_S_PROF/nemo_5km_'+nemo_run+'/'\n",
    "inputpath_isf='/bettik/burgardc/DATA/SUMMER_PAPER/interim/ANTARCTICA_IS_MASKS/nemo_5km_'+nemo_run+'/'\n",
    "\n",
    "# make the domain a little smaller to make the computation even more efficient - file isf has already been made smaller at its creation\n",
    "map_lim = [-3000000,3000000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "PREPARE MASK AROUND FRONT (TO RUN WITHOUT DASK!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "yy_ex = 2014\n",
    "#T_S_ocean_1980 = xr.open_dataset(inputpath_profiles+'T_S_theta_ocean_corrected_1990.nc')\n",
    "T_S_ocean_1980 = xr.open_dataset(inputpath_profiles+'T_S_theta_ocean_corrected_'+str(yy_ex)+'.nc')\n",
    "file_isf_orig = xr.open_dataset(inputpath_isf+'nemo_5km_isf_masks_and_info_and_distance_oneFRIS.nc')\n",
    "nonnan_Nisf = file_isf_orig['Nisf'].where(np.isfinite(file_isf_orig['front_bot_depth_max']), drop=True).astype(int)\n",
    "file_isf = file_isf_orig.sel(Nisf=nonnan_Nisf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_mask_orig = xr.open_dataset(inputpath_data+'other_mask_vars_Ant_stereo.nc')\n",
    "file_mask = uf.cut_domain_stereo(file_mask_orig, map_lim, map_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon = file_isf['longitude']\n",
    "lat = file_isf['latitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocean = np.isfinite(T_S_ocean_1980['theta_ocean'].isel(time=0,depth=0)).drop('time').drop('depth')\n",
    "# only points below 1500 m\n",
    "offshore = file_mask['bathy_metry'] > 1500 # .drop('lon').drop('lat')\n",
    "# only points above 1500 m\n",
    "contshelf = file_mask['bathy_metry'] <= 1500 # .drop('lon').drop('lat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_50km = (ocean & contshelf).load()\n",
    "\n",
    "lon_box = np.array([10.0])\n",
    "lat_box = np.array([3.5])\n",
    "\n",
    "close_region_around_isf_mask = tspf.mask_boxes_around_IF_new(lon, lat, mask_50km, \n",
    "                                file_isf['front_min_lon'], file_isf['front_max_lon'], \n",
    "                                file_isf['front_min_lat'], file_isf['front_max_lat'],  \n",
    "                                lon_box, lat_box, \n",
    "                                file_isf['isf_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_isf_points_from_line_small_domain(isf_points_da,line_points_da):\n",
    "    \n",
    "    \"\"\"\n",
    "    Compute the distance between ice shelf points and a line.\n",
    "    \n",
    "    This function computes the distance between ice shelf points and a line. This line can be the grounding\n",
    "    line or the ice shelf front.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    whole_domain : xarray.DataArray\n",
    "        ice-shelf mask - all ice shelves are represented by a number, all other points (ocean, land) set to nan\n",
    "    isf_points_da : xarray.DataArray\n",
    "        array containing only points from one ice shelf\n",
    "    line_points_da : xarray.DataArray\n",
    "        mask representing the grounding line or ice shelf front mask corresponding to the ice shelf selected in ``isf_points_da``\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    xr_dist_to_line : xarray.DataArray\n",
    "        distance of the each ice shelf point to the given line of interest\n",
    "    \"\"\"\n",
    "    \n",
    "    # add a common dimension 'grid' along which to stack\n",
    "    stacked_isf_points = isf_points_da.stack(grid=['y', 'x'])\n",
    "    stacked_line = line_points_da.stack(grid=['y', 'x'])\n",
    "    \n",
    "    # remove nans\n",
    "    filtered_isf_points = stacked_isf_points[stacked_isf_points>0]\n",
    "    filtered_line = stacked_line[stacked_line>0]\n",
    "    \n",
    "    # write out the y,x pairs behind the dimension 'grid'\n",
    "    grid_isf_points = filtered_isf_points.indexes['grid'].to_frame().values.astype(float)\n",
    "    grid_line = filtered_line.indexes['grid'].to_frame().values.astype(float)\n",
    "    \n",
    "    # create tree to line and compute distance\n",
    "    tree_line = cKDTree(grid_line)\n",
    "    dist_yx_to_line, _ = tree_line.query(grid_isf_points)\n",
    "        \n",
    "    # add the coordinates of the previous variables\n",
    "    xr_dist_to_line = filtered_isf_points.copy(data=dist_yx_to_line)\n",
    "    # put 1D array back into the format of the grid and put away the 'grid' dimension\n",
    "    xr_dist_to_line = xr_dist_to_line.unstack('grid')\n",
    "    \n",
    "    return xr_dist_to_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "close_region_around_isf_mask.profile_domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "IF_region.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "close_region_around_isf_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_list = [ ]\n",
    "for kisf in file_isf['Nisf']:\n",
    "\n",
    "        if (file_isf['IF_mask']==kisf).sum() > 0:\n",
    "            region_to_cut_out = close_region_around_isf_mask.sel(Nisf=kisf).squeeze()\n",
    "            region_to_cut_out = region_to_cut_out.where(region_to_cut_out > 0, drop=True)\n",
    "            IF_region = file_isf['IF_mask'].where(file_isf['IF_mask']==kisf, drop=True)\n",
    "\n",
    "            dist_from_front = distance_isf_points_from_line_small_domain(region_to_cut_out,IF_region)\n",
    "            dist_list.append(dist_from_front)\n",
    "\n",
    "dist_all = xr.concat(dist_list, dim='Nisf').reindex_like(file_isf)\n",
    "dist_all.to_dataset(name='dist_from_front').to_netcdf(inputpath_profiles+'dist_to_ice_front_only_contshelf.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "COMPUTING THE MEAN PROFILES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "CONTINENTAL SHELF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "bbox_da = xr.DataArray(np.array([10000., 25000., 50000., 100000.]), coords=[('dist_from_front', [10,25,50,100])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_domain_distkm = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "If workers don't die (with 12 cores, took approx 1hour), if workers die, divide work by years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_in_one = True # False if worker die, True if workers don't die\n",
    "if all_in_one:\n",
    "    dist_to_front_file = xr.open_mfdataset(inputpath_profiles+'dist_to_ice_front_only_contshelf.nc',chunks={'x': 50, 'y': 50})\n",
    "    T_S_ocean_files = xr.open_mfdataset(inputpath_profiles+'T_S_theta_ocean_corrected_*.nc', chunks={'x': 50, 'y': 50, 'depth': 50}, parallel=True)\n",
    "    #T_S_ocean_1980 = xr.open_mfdataset(inputpath_profiles+'T_S_theta_ocean_corrected_1990.nc',chunks={'x': 50, 'y': 50, 'depth': 50})\n",
    "    T_S_ocean_1980 = xr.open_mfdataset(inputpath_profiles+'T_S_theta_ocean_corrected_'+str(yy_ex)+'.nc',chunks={'x': 50, 'y': 50, 'depth': 50})\n",
    "else:\n",
    "    dist_to_front_file = xr.open_mfdataset(inputpath_profiles+'dist_to_ice_front_only_contshelf.nc',chunks={'x': 100, 'y': 100})\n",
    "    T_S_ocean_files = xr.open_mfdataset(inputpath_profiles+'T_S_theta_ocean_corrected_*.nc', concat_dim='time', chunks={'x': 100, 'y': 100, 'depth': 50}, parallel=True)\n",
    "    #T_S_ocean_1980 = xr.open_mfdataset(inputpath_profiles+'T_S_theta_ocean_corrected_1990.nc',chunks={'x': 100, 'y': 100, 'depth': 50})\n",
    "    T_S_ocean_1980 = xr.open_mfdataset(inputpath_profiles+'T_S_theta_ocean_corrected_'+str(yy_ex)+'.nc',chunks={'x': 100, 'y': 100, 'depth': 50})\n",
    "dist_to_front = dist_to_front_file['dist_from_front']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_to_front_file_yy = xr.open_dataset(inputpath_profiles+'dist_to_ice_front_only_contshelf.nc').chunk({'Nisf': 5})\n",
    "dist_to_front = dist_to_front_file_yy['dist_from_front']\n",
    "mask_km = dist_to_front <= mask_domain_distkm\n",
    "\n",
    "#for yy in tqdm(range(yy_start,yy_end+1)):\n",
    "#for yy in tqdm(range(yy_start,2060)):\n",
    "for yy in tqdm(range(2060,yy_end+1)):\n",
    "    T_S_ocean_file_yy = xr.open_dataset(inputpath_profiles+'T_S_theta_ocean_corrected_'+str(yy)+'.nc').chunk({'depth': 5})\n",
    "    \n",
    "    ds_sum = (T_S_ocean_file_yy * mask_km).sum(['x','y'])\n",
    "    \n",
    "    mask_depth = T_S_ocean_file_yy['salinity_ocean'].squeeze().drop('time') > 0\n",
    "    mask_all = mask_km & mask_depth\n",
    "    \n",
    "    mask_sum = mask_all.sum(['x','y'])\n",
    "    mask_sum = mask_sum.load()\n",
    "    \n",
    "    ds_mean = ds_sum/mask_sum\n",
    "    ds_mean.to_netcdf(inputpath_profiles+'T_S_mean_prof_corrected_km_contshelf_'+str(yy)+'.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "TS_list = []\n",
    "for tt in range(yy_start,yy_end+1):\n",
    "    ds_tt = xr.open_dataset(inputpath_profiles+'T_S_mean_prof_corrected_km_contshelf_'+str(tt)+'.nc')\n",
    "    TS_list.append(ds_tt)\n",
    "TS_ds = xr.concat(TS_list, dim='time')\n",
    "TS_ds.to_netcdf(inputpath_profiles+'T_S_mean_prof_corrected_km_contshelf_allyy.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
