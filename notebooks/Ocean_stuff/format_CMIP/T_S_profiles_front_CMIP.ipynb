{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Mon Jul 24 11:36 2020\n",
    "\n",
    "This is a script to cut out the T and S in the 50 km in front of the ice front\n",
    "\n",
    "@author: Clara Burgard\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "- calculate the distance to the ice front for the small domain in front of the ice shelf\n",
    "- take the ocean points at distance of ~50 km of the ice front "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "\n",
    "import itertools\n",
    "\n",
    "import distributed\n",
    "import glob\n",
    "\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = distributed.Client(n_workers=8, dashboard_address=':8795', local_directory='/tmp', memory_limit='6GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "READ IN THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mod = 'UKESM1-0-LL' # 'EPM026','EPM031', 'EPM034'\n",
    "scenario = 'ssp245'\n",
    "\n",
    "if mod in ['CNRM-CM6-1','CNRM-ESM2-1']:\n",
    "    ens_run = 'r1i1p1f2'\n",
    "    to2300 = False\n",
    "elif mod in ['GISS-E2-1-H']:\n",
    "    ens_run = 'r1i1p1f2'\n",
    "    to2300 = True\n",
    "elif mod in ['ACCESS-CM2','ACCESS-ESM1-5','CESM2-WACCM','CanESM5','IPSL-CM6A-LR','MRI-ESM2-0']:\n",
    "    ens_run = 'r1i1p1f1'\n",
    "    to2300 = True\n",
    "elif mod in ['MPI-ESM1-2-HR','GFDL-CM4','GFDL-ESM4']:\n",
    "    ens_run = 'r1i1p1f1'\n",
    "    to2300 = False\n",
    "elif mod == 'UKESM1-0-LL':\n",
    "    ens_run = 'r4i1p1f2'\n",
    "    to2300 = True     \n",
    "elif mod == 'CESM2':\n",
    "    ens_run = 'r11i1p1f1'\n",
    "    to2300 = False        \n",
    "\n",
    "\n",
    "if scenario == 'historical':\n",
    "    yystart = 1980 #1850\n",
    "    yyend = 2014\n",
    "elif scenario == 'ssp245':\n",
    "    yystart = 2015\n",
    "    yyend = 2100  \n",
    "else:\n",
    "    if to2300:\n",
    "        yystart = 2015\n",
    "        yyend = 2300\n",
    "    else:\n",
    "        yystart = 2015\n",
    "        yyend = 2100   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputpath_data_orig='/bettik/jourdai1/OCEAN_DATA_CMIP6_STEREO/'+mod+'/'\n",
    "inputpath_profiles='/bettik/burgardc/DATA/SUMMER_PAPER/interim/T_S_PROF/CMIP/'\n",
    "inputpath_isf='/bettik/burgardc/DATA/SUMMER_PAPER/interim/ANTARCTICA_IS_MASKS/BedMachine_8km/'\n",
    "inputpath_BedMachine='/bettik/burgardc/DATA/SUMMER_PAPER/interim/'\n",
    "\n",
    "# make the domain a little smaller to make the computation even more efficient - file isf has already been made smaller at its creation\n",
    "map_lim = [-3000000,3000000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "COMPUTING THE MEAN PROFILES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "CONTINENTAL SHELF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_domain_distkm = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "CREATE SUM OF WEIGHTS (ONLY DO ONCE!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_to_front_file = xr.open_mfdataset(inputpath_profiles+'dist_to_ice_front_only_contshelf_8km.nc',chunks={'x': 300, 'y': 300, 'Nisf': 30})\n",
    "S_ocean_files = xr.open_mfdataset(inputpath_data_orig+'so_Oyr_'+mod+'_'+scenario+'_'+ens_run+'_*.nc', parallel=True, chunks={'x': 300, 'y': 300, 'depth': 50, 'time': 5})\n",
    "file_BedMachine_orig = xr.open_mfdataset(inputpath_BedMachine+'BedMachine_v2_aggregated8km_allvars.nc').sel(x=dist_to_front_file.x,y=dist_to_front_file.y).chunk({'x': 300, 'y': 300})\n",
    "grid_cell_area_file = xr.open_mfdataset(inputpath_BedMachine+'gridarea_ISMIP6_AIS_8000m_grid_Clara.nc').sel(x=dist_to_front_file.x,y=dist_to_front_file.y).chunk({'x': 300, 'y': 300})\n",
    "\n",
    "dist_to_front = dist_to_front_file['dist_from_front']\n",
    "ocean_conc = file_BedMachine_orig['ocean_conc']\n",
    "true_grid_cell_area = grid_cell_area_file['true_grid_cell_area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_km = dist_to_front <= mask_domain_distkm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocean_mask = ocean_conc > 0\n",
    "depth_mask = S_ocean_files.z >= file_BedMachine_orig['bed']\n",
    "ocean_and_depth = ocean_mask & depth_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_depth = ocean_and_depth\n",
    "mask_all = mask_km & mask_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_sum = (mask_all * ocean_conc * true_grid_cell_area).sum(['x','y'])\n",
    "mask_sum = mask_sum.load()\n",
    "mask_sum.to_dataset(name='mask_sum').to_netcdf(inputpath_profiles + 'mask_sum.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "CREATE SUM OF T AND S OVER THE DOMAIN OF INTEREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_to_front_file = xr.open_mfdataset(inputpath_profiles+'dist_to_ice_front_only_contshelf_8km.nc',chunks={'x': chunk_size, 'y': chunk_size, 'Nisf': 30})\n",
    "T_ocean_files = xr.open_mfdataset(inputpath_data_orig+'thetao_Oyr_'+mod+'_'+scenario+'_'+ens_run+'_*.nc', use_cftime=True, parallel=True, chunks={'x': chunk_size, 'y': chunk_size, 'depth': 50, 'time': 5})\n",
    "S_ocean_files = xr.open_mfdataset(inputpath_data_orig+'so_Oyr_'+mod+'_'+scenario+'_'+ens_run+'_*.nc', use_cftime=True, parallel=True, chunks={'x': chunk_size, 'y': chunk_size, 'depth': 50, 'time': 5}) #, chunks={'x': 300, 'y': 300, 'depth': 50, 'time': 5})\n",
    "mask_sum = xr.open_dataset(inputpath_profiles + 'mask_sum.nc', chunks={'x': chunk_size, 'y': chunk_size, 'Nisf': 30})\n",
    "file_BedMachine_orig = xr.open_mfdataset(inputpath_BedMachine+'BedMachine_v2_aggregated8km_allvars.nc').sel(x=dist_to_front_file.x,y=dist_to_front_file.y).chunk({'x': chunk_size, 'y': chunk_size})\n",
    "grid_cell_area_file = xr.open_mfdataset(inputpath_BedMachine+'gridarea_ISMIP6_AIS_8000m_grid_Clara.nc').sel(x=dist_to_front_file.x,y=dist_to_front_file.y).chunk({'x': chunk_size, 'y': chunk_size})\n",
    "\n",
    "dist_to_front = dist_to_front_file['dist_from_front']\n",
    "ocean_conc = file_BedMachine_orig['ocean_conc']\n",
    "true_grid_cell_area = grid_cell_area_file['true_grid_cell_area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_km = dist_to_front <= mask_domain_distkm\n",
    "ocean_mask = ocean_conc > 0\n",
    "depth_mask = S_ocean_files.z >= file_BedMachine_orig['bed']\n",
    "ocean_and_depth = ocean_mask & depth_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_ocean_mask = (mask_km * ocean_conc * ocean_and_depth * true_grid_cell_area)#.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "for yy in tqdm(range(yystart,yyend+1)):\n",
    "#for yy in tqdm(range(2252,yyend+1)):\n",
    "    tt = T_ocean_files.time.where(T_ocean_files.time.dt.year == yy, drop=True)[0]\n",
    "    #print(tt.values)\n",
    "    ds_T_sum = (T_ocean_files['thetao'].sel(time=tt) * weighted_ocean_mask).sum(['x','y'])#.load()\n",
    "    ds_T_mean = (ds_T_sum/mask_sum['mask_sum'])\n",
    "    \n",
    "    ds_T_mean.to_dataset(name='thetao').to_netcdf(inputpath_profiles + mod + '/T_mean_prof_50km_contshelf_'+mod+'_'+scenario+'_'+str(yy)+'.nc')\n",
    "    \n",
    "    tt = S_ocean_files.time.where(S_ocean_files.time.dt.year == yy, drop=True)[0]\n",
    "    #print(tt.values)\n",
    "    ds_S_sum = (S_ocean_files['so'].sel(time=tt) * weighted_ocean_mask).sum(['x','y']) #.load()\n",
    "    ds_S_mean = (ds_S_sum/mask_sum['mask_sum'])\n",
    "    \n",
    "    ds_S_mean.to_dataset(name='so').to_netcdf(inputpath_profiles + mod + '/S_mean_prof_50km_contshelf_'+mod+'_'+scenario+'_'+str(yy)+'.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "for yy in tqdm(range(yystart,yyend+1)):\n",
    "    tt = S_ocean_files.time.where(S_ocean_files.time.dt.year == yy, drop=True)[0]\n",
    "    #print(tt.values)\n",
    "    ds_S_sum = (S_ocean_files['so'].sel(time=tt) * weighted_ocean_mask).sum(['x','y']) #.load()\n",
    "    ds_S_mean = (ds_S_sum/mask_sum['mask_sum'])\n",
    "    \n",
    "    ds_S_mean.to_dataset(name='so').to_netcdf(inputpath_profiles + mod + '/S_mean_prof_50km_contshelf_'+mod+'_'+scenario+'_'+str(yy)+'.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "This worked well with chunked T but not with S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for tt in T_ocean_files['thetao'].time:\n",
    "for yy in range(2015,2101):\n",
    "    tt = T_ocean_files.time.where(T_ocean_files.time.dt.year == yy, drop=True)[0]\n",
    "    print(tt.values)\n",
    "    ds_T_sum = (T_ocean_files['thetao'].sel(time=tt) * weighted_ocean_mask).sum(['x','y'])\n",
    "    #ds_S_sum = (S_ocean_files['so'].sel(time=tt) * weighted_ocean_mask).sum(['x','y'])\n",
    "\n",
    "    ds_T_mean = (ds_T_sum/mask_sum['mask_sum'])\n",
    "    #ds_S_mean = (ds_S_sum/mask_sum['mask_sum'])\n",
    "    \n",
    "    ds_T_mean.to_dataset(name='thetao').to_netcdf(inputpath_profiles + mod + '/T_mean_prof_50km_contshelf_'+mod+'_'+scenario+'_'+str(yy)+'.nc')\n",
    "    #ds_S_mean.to_dataset(name='so').to_netcdf(inputpath_profiles + mod + '/S_mean_prof_50km_contshelf_'+mod+'_'+scenario+'_'+str(yy)+'.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#T_S_mean = xr.merge([ds_T_mean,ds_S_mean]).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_S_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "TS_list = []\n",
    "for tt in range(yy_start,yy_end+1):\n",
    "    ds_tt = xr.open_dataset(inputpath_profiles+'T_S_mean_prof_corrected_km_contshelf_'+str(tt)+'.nc')\n",
    "    TS_list.append(ds_tt)\n",
    "TS_ds = xr.concat(TS_list, dim='time')\n",
    "TS_ds.to_netcdf(inputpath_profiles+'T_S_mean_prof_corrected_km_contshelf_allyy.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
