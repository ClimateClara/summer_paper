{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3338746f-330b-42bd-8e1a-827a74df5dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Prepare the masks of the ice shelves based on BedMachine\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af733bb4-17ac-4330-b1bd-b1cbaa3a02fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from pyproj import Transformer\n",
    "import pandas as pd\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import cc3d\n",
    "\n",
    "\n",
    "import multimelt.plume_functions as pf\n",
    "import multimelt.box_functions as bf\n",
    "import multimelt.useful_functions as uf\n",
    "import basal_melt_param.create_isf_mask_functions as isfmf\n",
    "\n",
    "import distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c58f4f-3db0-45fc-b853-3553ca5cff3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b4b9c1-8a52-4f49-b62b-18c875aef474",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_lim = [-3000000,3000000]\n",
    "\n",
    "#chunk_size = 700\n",
    "chunk_size = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e165f05a-e50a-4958-a1af-894d8dbb09de",
   "metadata": {},
   "source": [
    "READ IN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3a9667-a1e3-4c8d-b248-f0c05fe21360",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputpath_data='/bettik/burgardc/DATA/SUMMER_PAPER/interim/'\n",
    "inputpath_metadata='/bettik/burgardc/SCRIPTS/basal_melt_param/data/raw/MASK_METADATA/'\n",
    "outputpath_mask ='/bettik/burgardc/DATA/SUMMER_PAPER/interim/ANTARCTICA_IS_MASKS/BedMachine_4km/'\n",
    "outputpath_boxes = '/bettik/burgardc/DATA/SUMMER_PAPER/interim/BOXES/BedMachine_4km/'\n",
    "outputpath_plumes = '/bettik/burgardc/DATA/SUMMER_PAPER/interim/PLUMES/BedMachine_4km/'\n",
    "\n",
    "file_mask_orig = xr.open_dataset(inputpath_data+'BedMachine_v2_aggregated4km_allvars.nc')\n",
    "file_mask_orig_cut = uf.cut_domain_stereo(file_mask_orig, map_lim, map_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330f5497-54ad-4117-b6c1-092c170c43dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_msk = file_mask_orig_cut['mask_0_1_2']  #0 = ocean, 1 = ice shelves, 2 = grounded ice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cb8651-8daa-48ce-8f5d-57a2d550ce2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_bed_orig = -1*file_mask_orig_cut['bed']\n",
    "file_draft = (file_mask_orig_cut['thickness'] - file_mask_orig_cut['surface']).where(file_msk==1)\n",
    "file_isf_conc = file_mask_orig_cut['isf_conc']\n",
    "\n",
    "xx = file_msk['x']\n",
    "yy = file_msk['y']\n",
    "\n",
    "dx = abs(xx[1] - xx[0])\n",
    "dy = abs(yy[1] - yy[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a4be0e-8081-448d-85c7-c59626d6719b",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # do some fine-tuning for overlapping ice shelves   \n",
    "        problem_regions = [2,3,8,9,10,13,23,26,27,28,29,32,34,38,44,46,50,57,59,60,\n",
    "                   63,70,71,72,73,74,76,77,78,83,84,85,89,91,96,103]\n",
    "        \n",
    "        for conn_label in range(1,labels_out.max()):\n",
    "            basins_conn_domain = arr_def_ismask['ID_isf'].where(labelled_isf == conn_label, drop=True)\n",
    "            max_label = basins_conn_domain.max().values\n",
    "            min_label = basins_conn_domain.min().values\n",
    "            \n",
    "            # for areas with two labels in problem regions, take the one with the most points\n",
    "            if max_label != min_label:\n",
    "                groups_isf = basins_conn_domain.groupby(basins_conn_domain)\n",
    "                groups_labels = groups_isf.groups.keys()\n",
    "                if groups_isf.count().ID_isf.count() > 1:\n",
    "                    if any(x in problem_regions for x in list(groups_labels)):\n",
    "                        #print(conn_label)\n",
    "                        #print(min_label,max_label)\n",
    "                        dominant_isf = groups_isf.count().idxmax().values\n",
    "                        if dominant_isf == 12:\n",
    "                            dominant_isf = 14\n",
    "                        #print(dominant_isf)\n",
    "                        new_mask = new_mask.where(labelled_isf != conn_label, dominant_isf)\n",
    "            \n",
    "        # other fine-tuning: if an ice shelf is split, keep the largest connected domain\n",
    "        dx = abs(file_conc.x[1] - file_conc.x[0])\n",
    "        dy = abs(file_conc.y[1] - file_conc.y[0])\n",
    "\n",
    "        split_regions = [70,77,83,89,103] \n",
    "\n",
    "        for rreg in split_regions:\n",
    "            # look where there are the same labels in several unconnected domains\n",
    "            labels_same = list(new_mask.groupby(labelled_isf).groups) * (new_mask.groupby(labelled_isf).median() == rreg)\n",
    "            labels_same = labels_same[labels_same>0]\n",
    "\n",
    "            area_before = 0\n",
    "            for conn_label in labels_same:\n",
    "                # compute the area of the different unconnected areas\n",
    "                conc_for_area = file_conc.where(labelled_isf == conn_label, drop=True)\n",
    "                area_now = (conc_for_area * dx * dy).sum()\n",
    "                if area_now >= area_before:\n",
    "                    area_before = area_now\n",
    "                    largest_label = conn_label\n",
    "\n",
    "            # set the smaller areas to 159\n",
    "            for small_label in (labels_same.where(labels_same != largest_label).dropna('labels')):\n",
    "                new_mask = new_mask.where(labelled_isf != small_label, 159)\n",
    "\n",
    "        new_mask = new_mask + 1\n",
    "        new_mask_info = arr_def_ismask.copy()\n",
    "        new_mask_info['Nisf'] = new_mask_info['Nisf'] + 1\n",
    "        \n",
    "        new_mask = new_mask.where(file_msk != 0, 1).where(file_msk != 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c563d03f-12f9-4534-abda-80d3fab15d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def def_isf_mask(arr_def_ismask, file_msk, file_conc, lon, lat, FRIS_one=True, \n",
    "                 IMBIE_mask=True, variable_geometry=False, connectivity = 4, threshold = 4):\n",
    "    \n",
    "    \"\"\"\n",
    "    Define a mask for the individual ice shelves. \n",
    "    \n",
    "    This function defines a mask for the individual ice shelves. I think it works for both stereographic and latlon grids but I have not tried the latter.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    arr_def_ismask : np.array\n",
    "        Array containing minlon,maxlon,minlat,maxlat,is_nb or xr.Dataset with drainage basins\n",
    "    file_msk : xr.DataArray\n",
    "        Mask separating ocean (0), ice shelves (between 0 and 2, excluding 0 and 2), grounded ice (2) \n",
    "    file_conc : xr.DataArray\n",
    "        Ice shelf concentration for each point (between 0 and 1)\n",
    "    lon : xr.DataArray\n",
    "        Longitude (depends on x,y for stereographic)\n",
    "    lat : xr.DataArray\n",
    "        Latitude (depends on x,y for stereographic)\n",
    "    FRIS_one : Boolean \n",
    "        If True, Filchner-Ronne are considered as one ice-shelf\n",
    "    mouginot_basins : Boolean \n",
    "        If True, arr_def_ismask is an xr.DataArray with drainage basins\n",
    "    variable_geometry : Boolean \n",
    "        If True, arr_def_ismask\n",
    "    connectivity : int\n",
    "        4 or 8 for 2D, defines what is considered a \"connected\" point\n",
    "    threshold : int\n",
    "        Size of lonely pixel areas to remove\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    new_mask : xr.DataArray\n",
    "        Array showing the coverage of each ice shelf with the respective ID, open ocean is 1, land is 0\n",
    "    \"\"\"    \n",
    "    \n",
    "    if IMBIE_mask:\n",
    "        \n",
    "        isf_mask = file_msk.copy()\n",
    "        # only ice shelves\n",
    "        isf_only_mask = file_conc > 0\n",
    "        \n",
    "        #find connected components\n",
    "        dusted = cc3d.dust(isf_only_mask.values.astype(np.int64), \n",
    "                   threshold = threshold, \n",
    "                   connectivity = connectivity, \n",
    "                   in_place = False)\n",
    "        \n",
    "        labels_out = cc3d.connected_components(dusted, \n",
    "                                       connectivity = connectivity)\n",
    "        \n",
    "        labelled = xr.DataArray(labels_out, \n",
    "                        coords = {\"y\": file_conc.y, \"x\": file_conc.x}, \n",
    "                        dims = [\"y\", \"x\"],\n",
    "                        name = \"labels\")\n",
    "        \n",
    "        # assign ID for basins\n",
    "        isf_mask_basins = arr_def_ismask['Iceshelf_extrap'].where(isf_only_mask > 0)\n",
    "        # cut connected areas to area covered by basin stuff\n",
    "        labelled_isf = labelled.where(np.isfinite(isf_mask_basins))\n",
    "        \n",
    "        # creating the mask\n",
    "        new_mask = isf_mask_basins.copy()\n",
    "        \n",
    "        new_mask = new_mask.where(\n",
    "            new_mask != 58, 57).where(\n",
    "            new_mask != 151, 99).where(\n",
    "            new_mask != 109, 107).where(\n",
    "            new_mask != 116, 5).where(\n",
    "            new_mask != 143, 97).where(\n",
    "            new_mask != 137, 99)\n",
    "        \n",
    "                    \n",
    "        arr_def_ismask['isf_name'].loc[{'Nisf': 57}] = 'Ross'\n",
    "        arr_def_ismask['isf_name'].loc[{'Nisf': 58}] = np.nan\n",
    "        \n",
    "        if FRIS_one:\n",
    "            new_mask = new_mask.where(new_mask != 104, 103)\n",
    "            arr_def_ismask['isf_name'].loc[{'Nisf': 103}] = 'Filchner-Ronne'\n",
    "            arr_def_ismask['isf_name'].loc[{'Nisf': 104}] = np.nan\n",
    "\n",
    "        arr_def_ismask['isf_name'] = arr_def_ismask['isf_name'].dropna('Nisf')\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    if IMBIE_mask:\n",
    "        mask_file = new_mask.rename('ISF_mask'), \n",
    "\n",
    "    else:\n",
    "        mask_file = new_mask\n",
    "    \n",
    "    return mask_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f2d556-a457-4bde-b5d4-1fb933bb4a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "isf_mask_IMBIE = xr.open_dataset(inputpath_data + '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44632b7f-0a22-4cd7-914c-889307a977dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('handling coordinates')\n",
    "\n",
    "### Create latlon coordinates\n",
    "meshx, meshy = np.meshgrid(xx,yy)\n",
    "meshlon,meshlat = uf.change_coord_stereo_to_latlon(meshx,meshy)\n",
    "file_msk['longitude'] = (['y', 'x'],  meshlon)\n",
    "file_msk['latitude'] = (['y', 'x'],  meshlat)\n",
    "lon = file_msk['longitude']\n",
    "lat = file_msk['latitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f13f72-10bd-4c2b-a099-95cf8a053881",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_conc = file_isf_conc\n",
    "arr_def_ismask = isf_mask_IMBIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0e3163-ed5f-4b3d-a325-850f6acf260a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_test = def_isf_mask(isf_mask_IMBIE, file_msk, file_isf_conc, lon, lat, FRIS_one=True, \n",
    "                 IMBIE_mask=True, variable_geometry=False, connectivity = 4, threshold = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdfb38e-7cb0-48d1-9f8a-f7d468f0e18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "isf_mask = file_msk.copy()\n",
    "# only ice shelves\n",
    "isf_only_mask = file_conc > 0\n",
    "\n",
    "# assign ID for basins\n",
    "isf_mask_basins = arr_def_ismask['Iceshelf_extrap'].where(isf_only_mask > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb4da69-6e9e-403b-ba0c-e3d99f51e7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "isf_mask_basins.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6474318-109c-40a2-8cc5-7e6f97db44bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "FRIS_one=True\n",
    "\n",
    "# creating the mask\n",
    "new_mask = isf_mask_basins.copy()\n",
    "\n",
    "arr_def_ismask['isf_name'].loc[{'Nisf': 57}] = 'Ross'\n",
    "arr_def_ismask['isf_name'].loc[{'Nisf': 58}] = np.nan\n",
    "\n",
    "if FRIS_one:\n",
    "    new_mask = new_mask.where(new_mask != 104, 103)\n",
    "    arr_def_ismask['isf_name'].loc[{'Nisf': 103}] = 'Filchner-Ronne'\n",
    "    arr_def_ismask['isf_name'].loc[{'Nisf': 104}] = np.nan\n",
    "\n",
    "arr_def_ismask['isf_name'] = arr_def_ismask['isf_name'].dropna('Nisf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013fbd00-68b0-467d-a9a8-58323c93a36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#whole_ds = isfmf.create_mask_and_metadata_isf(file_msk, -1*file_bed_orig, file_msk, -1*file_draft, file_isf_conc, False, \n",
    "#                                          inputpath_metadata+'lonlat_masks.txt', outputpath_mask, \n",
    "#                                          inputpath_metadata + 'iceshelves_metadata_Nico.txt', \n",
    "#                                          inputpath_metadata+'GL_flux_rignot13.csv', mouginot_basins=True, variable_geometry=False,\n",
    "#                                          write_ismask = 'yes', write_groundmask = 'yes', write_outfile='yes',\n",
    "#                                          ground_point ='no',dist=40, add_fac=120, connectivity=4, threshold=4,\n",
    "#                                          write_metadata='yes')\n",
    "\n",
    "whole_ds = isfmf.create_mask_and_metadata_isf(file_msk, -1*file_bed_orig, file_msk, -1*file_draft, file_isf_conc, False, \n",
    "                                          inputpath_data+'Mask_Iceshelf_4km_IMBIE_withNisf.nc', outputpath_mask, \n",
    "                                          inputpath_metadata + 'iceshelves_metadata_Nico.txt', \n",
    "                                          inputpath_metadata+'GL_flux_rignot13.csv', mouginot_basins=True, variable_geometry=False,\n",
    "                                          write_ismask = 'yes', write_groundmask = 'yes', write_outfile='yes',\n",
    "                                          ground_point ='no',dist=40, add_fac=120, connectivity=4, threshold=4,\n",
    "                                          write_metadata='yes')\n",
    "\n",
    "# Write to netcdf\n",
    "print('------- WRITE TO NETCDF -----------')\n",
    "#whole_ds.to_netcdf(outputpath_mask + 'BedMachine_4km_isf_masks_and_info_and_distance_oneFRIS.nc','w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fa2b15-7164-42dc-93ac-fd7a90c6ceb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_bed_orig = -1*file_mask_orig_cut['bed']\n",
    "file_draft = (file_mask_orig_cut['thickness'] - file_mask_orig_cut['surface']).where(file_msk==1)\n",
    "file_isf_conc = file_mask_orig_cut['isf_conc']\n",
    "file_msk = file_mask_orig_cut['mask_0_1_2']  #0 = ocean, 1 = ice shelves, 2 = grounded ice\n",
    "\n",
    "xx = file_mask_orig_cut['x']\n",
    "yy = file_mask_orig_cut['y']\n",
    "\n",
    "whole_ds_tt = xr.open_dataset(outputpath_mask + 'BedMachine_4km_isf_masks_and_info_and_distance_oneFRIS.nc')\n",
    "\n",
    "nonnan_Nisf = whole_ds_tt['Nisf'].where(np.isfinite(whole_ds_tt['front_bot_depth_max']), drop=True).astype(int)\n",
    "file_isf_nonnan = whole_ds_tt.sel(Nisf=nonnan_Nisf)\n",
    "rignot_isf = file_isf_nonnan.Nisf.where(np.isfinite(file_isf_nonnan['isf_area_rignot']), drop=True)\n",
    "file_isf = file_isf_nonnan.sel(Nisf=rignot_isf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cea7a1-8051-41cc-b653-25b725118932",
   "metadata": {},
   "outputs": [],
   "source": [
    "isf_var_of_int = whole_ds_tt[['ISF_mask', 'GL_mask', 'dGL', 'dIF', 'latitude', 'longitude', 'isf_name']]\n",
    "out_2D, out_1D = bf.box_charac_file(file_isf['Nisf'],isf_var_of_int, -1*file_draft, file_isf_conc, outputpath_boxes, max_nb_box=10)\n",
    "out_2D.to_netcdf(outputpath_boxes + 'BedMachine_4km_boxes_2D_oneFRIS.nc')\n",
    "out_1D.to_netcdf(outputpath_boxes + 'BedMachine_4km_boxes_1D_oneFRIS.nc')\n",
    "    \n",
    "# double check here which ice shelves we want    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cb2621-2edb-4951-9bcd-e7be9759987a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plume_param_options = ['cavity','lazero', 'local']\n",
    "\n",
    "plume_var_of_int = file_isf[['ISF_mask', 'GL_mask', 'IF_mask', 'dIF', 'dGL_dIF', 'latitude', 'longitude', 'front_ice_depth_avg']]\n",
    "\n",
    "# Compute the ice draft\n",
    "ice_draft_pos = file_draft\n",
    "# Be careful with ice shelf 178 and 195 - they have a negative ice draft\n",
    "# I don't know how to fix it at the moment so I put it to nan\n",
    "#ice_draft_pos = ice_draft_pos.where(plume_var_of_int['ISF_mask'] != 178, np.nan)\n",
    "#ice_draft_pos = ice_draft_pos.where(plume_var_of_int['ISF_mask'] != 195, np.nan)\n",
    "\n",
    "ice_draft_neg = -1*ice_draft_pos\n",
    "\n",
    "\n",
    "plume_charac = pf.prepare_plume_charac(plume_param_options, ice_draft_pos, plume_var_of_int)\n",
    "print('------ WRITE TO NETCDF -------')\n",
    "plume_charac.to_netcdf(outputpath_plumes+'BedMachine_4km_plume_characteristics.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e95135-68e8-47f7-8b51-9fd88410b406",
   "metadata": {},
   "source": [
    "DO THE MASKS FOR 8 KM GRID AS WELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38018fd-897e-46ce-b978-1ae0a658abbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputpath_data='/bettik/burgardc/DATA/SUMMER_PAPER/interim/'\n",
    "inputpath_metadata='/bettik/burgardc/SCRIPTS/basal_melt_param/data/raw/MASK_METADATA/'\n",
    "outputpath_mask ='/bettik/burgardc/DATA/SUMMER_PAPER/interim/ANTARCTICA_IS_MASKS/BedMachine_8km/'\n",
    "\n",
    "\n",
    "file_mask_orig = xr.open_dataset(inputpath_data+'BedMachine_v3_aggregated8km_allvars.nc')\n",
    "file_mask_orig_cut = uf.cut_domain_stereo(file_mask_orig, map_lim, map_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97501ab7-d4c8-47a6-80e9-fe7cb6f71b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_msk = file_mask_orig_cut['mask_0_1_2']  #0 = ocean, 1 = ice shelves, 2 = grounded ice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9764457e-2104-4477-ab7c-f5c61bbce570",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_bed_orig = -1*file_mask_orig_cut['bed']\n",
    "file_draft = (file_mask_orig_cut['thickness'] - file_mask_orig_cut['surface']).where(file_msk==1)\n",
    "file_isf_conc = file_mask_orig_cut['isf_conc']\n",
    "\n",
    "xx = file_msk['x']\n",
    "yy = file_msk['y']\n",
    "\n",
    "dx = abs(xx[1] - xx[0])\n",
    "dy = abs(yy[1] - yy[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f671e5-4121-4816-826a-94e20b28a7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_ds = isfmf.create_mask_and_metadata_isf(file_msk, -1*file_bed_orig, file_msk, -1*file_draft, file_isf_conc, False, \n",
    "                                          inputpath_metadata+'lonlat_masks.txt', outputpath_mask, \n",
    "                                          inputpath_metadata + 'iceshelves_metadata_Nico.txt', \n",
    "                                          inputpath_metadata+'GL_flux_rignot13.csv', mouginot_basins=False, variable_geometry=False,\n",
    "                                          write_ismask = 'yes', write_groundmask = 'yes', write_outfile='yes',\n",
    "                                          ground_point ='no',dist=40, add_fac=120, connectivity=4, threshold=4,\n",
    "                                          write_metadata='yes')\n",
    "\n",
    "# Write to netcdf\n",
    "print('------- WRITE TO NETCDF -----------')\n",
    "whole_ds.to_netcdf(outputpath_mask + 'BedMachine_8km_isf_masks_and_info_and_distance_oneFRIS.nc','w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f86da8-7b64-4dd0-9a91-a329ff79428c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
